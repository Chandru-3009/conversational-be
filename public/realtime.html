<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nutrina Voice Agent - OpenAI Realtime</title>
    <link rel="stylesheet" href="style.css">
</head>

<body>
    <div class="container">
        <div class="header">
            <h1>Nutrina Voice Agent - OpenAI Realtime</h1>
            <p>Real-time voice conversation using Web Speech API and OpenAI Realtime API</p>
        </div>

        <div id="status" class="status disconnected">
            Disconnected
        </div>

        <div id="userEmailSection" class="user-email-section">
            <label for="userEmail">Email Address *</label>
            <input type="email" id="userEmail" placeholder="Enter your email address" class="email-input" required>
            <small>Required for personalized experience and data tracking</small>
        </div>

        <div id="sessionInfo" class="session-info" style="display: none;">
            Session ID: <span id="sessionId"></span>
        </div>

        <div id="error" class="error" style="display: none;"></div>
        <div id="success" class="success" style="display: none;"></div>

        <div class="controls">
            <button id="connectBtn" class="btn btn-primary">üîó Connect</button>
            <button id="disconnectBtn" class="btn btn-secondary" disabled>üö´ Disconnect</button>
            <button id="startCallBtn" class="btn btn-primary" disabled>üìû Start Call</button>
            <button id="endCallBtn" class="btn btn-secondary" disabled>üì¥ End Call</button>
        </div>

        <div id="callStatus" class="call-status" style="display: none;">
            Ready to call
        </div>

        <div id="speechControls" class="speech-controls" style="display: none;">
            <div class="speech-status">
                <span>Speech Recognition: </span>
                <span id="speechStatus">Not Active</span>
            </div>
            <button id="startListeningBtn" class="btn btn-success">üé§ Start Listening</button>
            <button id="stopListeningBtn" class="btn btn-warning" disabled>‚èπÔ∏è Stop Listening</button>
        </div>

        <div id="webrtcStatus" class="webrtc-status" style="display: none;">
            <div class="status-item">
                <span>WebRTC Connection: </span>
                <span id="webrtcConnectionStatus">Disconnected</span>
            </div>
            <div class="status-item">
                <span>Data Channel: </span>
                <span id="dataChannelStatus">Closed</span>
            </div>
        </div>

        <div id="recordingIndicator" class="recording-indicator" style="display: none;">
            <div class="recording-dot"></div>
            <span>Listening...</span>
        </div>

        <div class="conversation" id="conversation">
            <div class="message ai">
                <div>Welcome! Click "Connect" and then "Start Call" to begin your real-time voice conversation with
                    Nutrina.
                </div>
                <div class="message-time">System</div>
            </div>
        </div>

        <div class="system-prompt-info"
            style="margin-top: 15px; padding: 10px; background: #f8f9fa; border-radius: 5px; font-size: 12px; color: #666;">
            <strong>üí° Tip:</strong> You can customize the AI's behavior by updating the system prompt.
            After starting a call, open the browser console and run:
            <code>client.updateSystemPrompt("Your custom prompt here")</code>
        </div>

        <div id="ssmlTestSection" class="ssml-test-section" style="display: none;">
            <h3>üéµ SSML Text-to-Speech Testing</h3>
            <p style="font-size: 14px; color: #666; margin-bottom: 15px;">
                Test different SSML structures to see how they sound. Make sure to use valid SSML tags like
                &lt;speak&gt;, &lt;break&gt;, &lt;prosody&gt;, etc.
            </p>
            <div class="ssml-test-controls">
                <textarea id="ssmlTestText" class="ssml-textarea"
                    placeholder="Enter SSML text here... Example:&#10;&lt;speak&gt;&#10;  Hello! This is a test of the text-to-speech functionality.&#10;  &lt;break time=&quot;300ms&quot;/&gt;&#10;  How does this sound?&#10;&lt;/speak&gt;"
                    rows="6"></textarea>
                <div class="ssml-test-buttons">
                    <button id="testSSMLBtn" class="btn btn-info">üîä Test SSML</button>
                    <button id="clearSSMLBtn" class="btn btn-outline-secondary">üóëÔ∏è Clear</button>
                </div>
            </div>
            <div class="ssml-examples">
                <details>
                    <summary style="cursor: pointer; color: #007bff; font-weight: 500;">üìù SSML Examples</summary>
                    <div style="margin-top: 10px; font-size: 13px;">
                        <div class="example-item">
                            <strong>Basic:</strong>
                            <code>&lt;speak&gt;Hello, this is a simple test.&lt;/speak&gt;</code>
                        </div>
                        <div class="example-item">
                            <strong>With pauses:</strong>
                            <code>&lt;speak&gt;Hello! &lt;break time="300ms"/&gt; This has a pause.&lt;/speak&gt;</code>
                        </div>
                        <div class="example-item">
                            <strong>With emphasis:</strong>
                            <code>&lt;speak&gt;This is &lt;emphasis level="moderate"&gt;important&lt;/emphasis&gt; text.&lt;/speak&gt;</code>
                        </div>
                        <div class="example-item">
                            <strong>With prosody:</strong>
                            <code>&lt;speak&gt;&lt;prosody rate="medium" pitch="+2%"&gt;Great!&lt;/prosody&gt; &lt;break time="300ms"/&gt; How are you?&lt;/speak&gt;</code>
                        </div>
                    </div>
                </details>
            </div>
        </div>
    </div>

    <script>
        class OpenAIRealtimeClient {
            constructor() {
                this.sessionId = null;
                this.userId = null;
                this.userEmail = null;
                this.ephemeralKey = null;
                this.peerConnection = null;
                this.dataChannel = null;
                this.isInCall = false;
                this.isConnected = false;
                this.isListening = false;
                this.speechRecognition = null;
                this.websocket = null;

                // Add tracking for realtime session response
                this.realtimeSessionRequestSent = false;
                this.realtimeSessionResponseReceived = false;
                this.realtimeSessionRetryCount = 0;
                this.maxRetries = 3;

                this.initializeElements();
                this.setupEventListeners();
                this.initializeSpeechRecognition();
            }

            initializeElements() {
                this.statusEl = document.getElementById('status');
                this.connectBtn = document.getElementById('connectBtn');
                this.disconnectBtn = document.getElementById('disconnectBtn');
                this.startCallBtn = document.getElementById('startCallBtn');
                this.endCallBtn = document.getElementById('endCallBtn');
                this.callStatus = document.getElementById('callStatus');
                this.recordingIndicator = document.getElementById('recordingIndicator');
                this.conversation = document.getElementById('conversation');
                this.sessionInfo = document.getElementById('sessionInfo');
                this.sessionIdSpan = document.getElementById('sessionId');
                this.errorEl = document.getElementById('error');
                this.successEl = document.getElementById('success');
                this.userEmailInput = document.getElementById('userEmail');

                // Speech controls
                this.speechControls = document.getElementById('speechControls');
                this.speechStatus = document.getElementById('speechStatus');
                this.startListeningBtn = document.getElementById('startListeningBtn');
                this.stopListeningBtn = document.getElementById('stopListeningBtn');

                // WebRTC status elements
                this.webrtcStatus = document.getElementById('webrtcStatus');
                this.webrtcConnectionStatus = document.getElementById('webrtcConnectionStatus');
                this.dataChannelStatus = document.getElementById('dataChannelStatus');

                // SSML test section elements
                this.ssmlTestSection = document.getElementById('ssmlTestSection');
                this.ssmlTestTextArea = document.getElementById('ssmlTestText');
                this.testSSMLBtn = document.getElementById('testSSMLBtn');
                this.clearSSMLBtn = document.getElementById('clearSSMLBtn');
            }

            setupEventListeners() {
                this.connectBtn.addEventListener('click', () => this.connect());
                this.disconnectBtn.addEventListener('click', () => this.disconnect());
                this.startCallBtn.addEventListener('click', () => this.startCall());
                this.endCallBtn.addEventListener('click', () => this.endCall());
                this.startListeningBtn.addEventListener('click', () => this.startListening());
                this.stopListeningBtn.addEventListener('click', () => this.stopListening());
                this.testSSMLBtn.addEventListener('click', () => this.testSSML());
                this.clearSSMLBtn.addEventListener('click', () => this.clearSSML());
            }

            // Method to update system prompt during the session
            updateSystemPrompt(newPrompt) {
                if (this.isInCall && this.dataChannel && this.dataChannel.readyState === 'open') {
                    this.setSystemPrompt(newPrompt);
                    this.showMessage('System prompt updated', 'ai');
                } else {
                    this.showError('Cannot update system prompt - call not active');
                }
            }

            // Test method for TTS functionality
            testTTS(text = "Hello, this is a test of the text-to-speech functionality.") {
                if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                    console.log('üß™ Testing TTS with text:', text);
                    this.websocket.send(JSON.stringify({
                        type: 'tts_request',
                        text: text,
                        sessionId: this.sessionId,
                    }));
                } else {
                    this.showError('WebSocket not connected');
                }
            }

            initializeSpeechRecognition() {
                // Check if Web Speech API is supported
                if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                    this.showError('Speech recognition is not supported in this browser.');
                    return;
                }

                // Initialize speech recognition
                const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                this.speechRecognition = new SpeechRecognition();

                this.speechRecognition.continuous = true;
                this.speechRecognition.interimResults = true;
                this.speechRecognition.lang = 'en-US';

                this.speechRecognition.onstart = () => {
                    console.log('üé§ Speech recognition started');
                    this.isListening = true;
                    this.speechStatus.textContent = 'Active';
                    this.startListeningBtn.disabled = true;
                    this.stopListeningBtn.disabled = false;
                    this.recordingIndicator.style.display = 'flex';
                };

                this.speechRecognition.onend = () => {
                    console.log('üîá Speech recognition ended');
                    this.isListening = false;
                    this.speechStatus.textContent = 'Not Active';
                    this.startListeningBtn.disabled = false;
                    this.stopListeningBtn.disabled = true;
                    this.recordingIndicator.style.display = 'none';
                };

                this.speechRecognition.onresult = (event) => {
                    let finalTranscript = '';
                    let interimTranscript = '';

                    for (let i = event.resultIndex; i < event.results.length; i++) {
                        const transcript = event.results[i][0].transcript;
                        if (event.results[i].isFinal) {
                            finalTranscript += transcript;
                        } else {
                            interimTranscript += transcript;
                        }
                    }

                    // If we have final results, send them to OpenAI
                    if (finalTranscript.trim()) {
                        console.log('üé§ Final transcript:', finalTranscript);
                        this.showMessage(finalTranscript, 'user');
                        this.sendTextToOpenAI(finalTranscript.trim());
                    }
                };

                this.speechRecognition.onerror = (event) => {
                    console.error('Speech recognition error:', event.error);
                    this.speechStatus.textContent = 'Error';
                    this.showError(`Speech recognition error: ${event.error}`);
                };
            }

            generateSessionId() {
                return 'realtime_session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
            }

            generateUserId() {
                return 'user_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
            }

            updateStatus(status, message) {
                this.statusEl.className = `status ${status}`;
                this.statusEl.textContent = message;
            }

            updateCallStatus(message) {
                this.callStatus.textContent = message;
            }

            showMessage(content, type = 'ai', timestamp = new Date()) {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${type}`;

                const contentDiv = document.createElement('div');
                contentDiv.textContent = content;

                const timeDiv = document.createElement('div');
                timeDiv.className = 'message-time';
                timeDiv.textContent = timestamp.toLocaleTimeString();

                messageDiv.appendChild(contentDiv);
                messageDiv.appendChild(timeDiv);

                this.conversation.appendChild(messageDiv);
                this.conversation.scrollTop = this.conversation.scrollHeight;
            }

            showError(message) {
                this.errorEl.textContent = message;
                this.errorEl.style.display = 'block';
                setTimeout(() => {
                    this.errorEl.style.display = 'none';
                }, 5000);
            }

            showSuccess(message) {
                this.successEl.textContent = message;
                this.successEl.style.display = 'block';
                setTimeout(() => {
                    this.successEl.style.display = 'none';
                }, 3000);
            }

            async connect() {
                try {
                    // Validate email is provided
                    const userEmail = this.userEmailInput.value.trim();
                    if (!userEmail) {
                        this.showError('Email address is required to connect.');
                        return;
                    }

                    // Basic email validation
                    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
                    if (!emailRegex.test(userEmail)) {
                        this.showError('Please enter a valid email address.');
                        return;
                    }

                    this.sessionId = this.generateSessionId();
                    this.userId = this.generateUserId();
                    this.userEmail = userEmail;

                    this.updateStatus('connecting', 'Connecting...');
                    this.connectBtn.disabled = true;

                    // Get the current host and port for WebSocket connection
                    let wsUrl = '';
                    const currentHost = window.location.hostname;
                    const currentPort = window.location.port || (window.location.protocol === 'https:' ? '443' : '80');

                    // Handle different scenarios
                    if (!currentHost || currentHost === 'localhost' || currentHost === '127.0.0.1') {
                        wsUrl = 'ws://localhost:3031';
                    } else {
                        // Production or remote server
                        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                        wsUrl = `${protocol}//${currentHost}:${currentPort === '80' ? '3031' : currentPort}`;
                    }

                    console.log('Using WebSocket URL:', wsUrl);

                    // Connect to WebSocket server
                    this.websocket = new WebSocket(`${wsUrl}?sessionId=${this.sessionId}&userEmail=${encodeURIComponent(userEmail)}`);

                    this.websocket.onopen = () => {
                        console.log('üîó WebSocket connected');
                        this.updateStatus('connected', 'Connected');
                        this.connectBtn.disabled = true;
                        this.disconnectBtn.disabled = false;
                        this.startCallBtn.disabled = false;
                        this.sessionInfo.style.display = 'block';
                        this.sessionIdSpan.textContent = this.sessionId;
                        this.callStatus.style.display = 'block';
                        this.webrtcStatus.style.display = 'block';
                        this.isConnected = true;

                        this.showSuccess(`Connected with email: ${userEmail}`);
                        this.showMessage('Connected successfully. Click "Start Call" to begin your voice conversation.', 'ai');
                    };

                    this.websocket.onmessage = (event) => {
                        try {
                            const message = JSON.parse(event.data);
                            this.handleWebSocketMessage(message);
                        } catch (error) {
                            console.error('Error parsing WebSocket message:', error);
                        }
                    };

                    this.websocket.onerror = (error) => {
                        console.error('WebSocket error:', error);
                        this.showError('WebSocket connection error');
                        this.updateStatus('disconnected', 'Connection failed');
                        this.connectBtn.disabled = false;
                        this.isConnected = false;
                    };

                    this.websocket.onclose = () => {
                        console.log('WebSocket connection closed');
                        this.updateStatus('disconnected', 'Disconnected');
                        this.connectBtn.disabled = false;
                        this.disconnectBtn.disabled = true;
                        this.startCallBtn.disabled = true;
                        this.isConnected = false;
                    };

                    // Send realtime session request
                    setTimeout(() => {
                        console.log('Sending realtime session request');
                        this.websocket.send(JSON.stringify({
                            type: 'realtime_session_request',
                            sessionId: this.sessionId,
                            userId: this.userId,
                            userEmail: this.userEmail,
                        }));
                    }, 500);


                } catch (error) {
                    console.error('Connection error:', error);
                    this.showError('Failed to connect: ' + error.message);
                    this.updateStatus('disconnected', 'Connection failed');
                    this.connectBtn.disabled = false;
                    this.isConnected = false;
                }
            }

            async startCall() {
                try {
                    if (!this.isConnected || !this.ephemeralKey) {
                        this.showError('Not connected or no ephemeral key available.');
                        return;
                    }

                    this.isInCall = true;
                    this.startCallBtn.disabled = true;
                    this.endCallBtn.disabled = false;
                    this.updateCallStatus('Initializing WebRTC connection...');

                    await this.initializeWebRTC();

                } catch (error) {
                    console.error('Error starting call:', error);
                    this.showError('Failed to start call: ' + error.message);
                    this.endCall();
                }
            }

            async initializeWebRTC() {
                try {
                    console.log('üîó Initializing WebRTC connection...');

                    // Create peer connection
                    this.peerConnection = new RTCPeerConnection({
                        iceServers: [
                            { urls: 'stun:stun.l.google.com:19302' },
                            { urls: 'stun:stun1.l.google.com:19302' }
                        ]
                    });

                    // Create data channel for text communication
                    this.dataChannel = this.peerConnection.createDataChannel('oai-events');
                    this.setupDataChannelHandlers();

                    // Add audio transceiver for OpenAI Realtime API
                    // This is required even for text-only communication
                    this.peerConnection.addTransceiver('audio', {
                        direction: 'sendrecv',
                        streams: []
                    });

                    // Connection state changes
                    this.peerConnection.onconnectionstatechange = () => {
                        console.log('WebRTC connection state:', this.peerConnection.connectionState);
                        this.webrtcConnectionStatus.textContent = this.peerConnection.connectionState;

                        if (this.peerConnection.connectionState === 'connected') {
                            this.updateCallStatus('Connected - Click "Start Listening" to speak!');
                            this.speechControls.style.display = 'block';
                            this.ssmlTestSection.style.display = 'block';
                            this.showMessage('WebRTC connected! Click "Start Listening" to begin speaking.', 'ai');

                            // Set system prompt for the session
                            setTimeout(() => {
                                this.setSystemPrompt(`You are Nutrina, a warm, caring, and friendly voice-powered diet tracking assistant. You are speaking directly to the user and helping them track their meals naturally and effortlessly. Your responses will be spoken aloud using text-to-speech, so they must sound like a real, confident, empathetic human.

‚úÖ TONE & STYLE GUIDELINES:
- Be warm, natural, and supportive ‚Äî like a caring companion
- Speak confidently ‚Äî avoid sounding hesitant or overly scripted
- Use natural, conversational language with micro reactions and emotions
- Instead of multiple sentence breaks, try to integrate them into a single, more fluid sentence
- Add light humor and encouragement with subtle personality quirks (see examples)
- Occasionally add a surprise or delight factor, such as a fun food fact or hydration tip, especially when contextually appropriate

üé≠ MICRO REACTIONS & EMOTIONS:
- Use natural micro reactions like: "Ooh", "Great!", "Nice", "Wow", "Mmm", "Ah", "Oh", "Hmm"
- Express micro emotions: "That sounds delicious", "How lovely", "That's wonderful", "Interesting", "Perfect"
- Use these naturally in conversation, not forced or overdone
- Examples: "Ooh, that sounds delicious! A small bowl of sambar. And how much rice did you have with that?"

üåü LIGHT HUMOR & ENCOURAGEMENT:
- Add playful, encouraging remarks and subtle personality quirks
- Examples:
  * "That‚Äôs a strong breakfast! Are we conquering the world today?"
  * "Wow, you're consistent with those smoothies! Gold star for you ü•á"
  * "You‚Äôre on a roll! If you keep this up, you‚Äôll need a trophy shelf."

üéÅ OCCASIONAL SURPRISES (DELIGHT FACTOR):
- Occasionally share a fun food fact or hydration tip, especially when it fits the context
- Examples:
  * "Did you know? Bananas are technically berries, but strawberries aren‚Äôt!"
  * "You‚Äôve logged three salty meals this week ‚Äî don‚Äôt forget to drink water!"
  * "Fun fact: Carrots were originally purple!"

FOOD & QUANTITY COLLECTION GUIDELINES:
- Focus on getting the food item and its quantity in a friendly, conversational way
- Use natural, human measurements instead of precise grams:
  * "a small bowl of", "a medium bowl of", "a large bowl of"
  * "one cup of", "half a cup of", "a coffee cup size of"
  * "one tablespoon of", "two tablespoons of", "a spoonful of"
  * "one slice of", "two slices of", "a few slices of"
  * "one piece of", "a small piece of", "a large piece of"
  * "one serving of", "a small serving of", "a generous serving of"
  * "one glass of", "half a glass of", "a small glass of"
  * "one plate of", "a small plate of", "a full plate of"
- Ask follow-up questions naturally: Example: "And how much rice did you have with that?" or "What about the portion size?"
- Don't ask for exact grams or precise measurements ‚Äî stick to everyday language
- Don't suggest recipes, meal plans, or alternative foods ‚Äî just focus on what they actually ate

SPEECH-TO-TEXT HANDLING:
- The user's response comes from speech-to-text conversion and may contain inaccuracies
- Make educated guesses based on context when words are unclear or misspelled
- If you're unsure about a food item, ask for clarification in a friendly way
- Common speech-to-text errors to watch for:
  * "rice" might be "rise", "ice", or "price"
  * "bread" might be "bred", "red", or "read"
  * "chicken" might be "kitchen", "chick in", or "chicken"
  * "soup" might be "soap", "soup", or "sue"
  * Numbers might be misheard: "two" vs "to", "one" vs "won"
- Use conversation context to interpret unclear responses
- If completely unclear, ask the user to repeat.

‚úÖ NATURAL EXAMPLES:

"Ooh, that sounds delicious! A small bowl of sambar. Got it. And how much rice did you have with that?"

"Great! A medium bowl of rice. That's a nice portion. And what about the vegetables?"

"You‚Äôve logged three salty meals this week ‚Äî don‚Äôt forget to drink water!"

‚ùå DO NOT:
- Ask for exact grams or precise measurements
- Suggest recipes or alternative meal options
- Sound scripted or robotic ‚Äî keep it conversational and human
- Overuse micro reactions ‚Äî use them naturally and sparingly
- Use formal or clinical language

PRIMARY OBJECTIVE: Get the food item and its quantity using natural, everyday language in a friendly, conversational manner with natural micro reactions, emotions, light humor, encouragement, and occasional surprises. Based on the time of interaction, get the Breakfast, Lunch, Dinner, Snack, or Drink. Focus on what they actually ate, not what they should eat.

ONLY return natural, conversational text that will be spoken by a TTS engine. Do not use SSML tags or explain your answer ‚Äî just output natural speech ready for text-to-speech.
`);
                            }, 1000);
                        } else if (this.peerConnection.connectionState === 'failed') {
                            this.showError('WebRTC connection failed');
                            this.endCall();
                        }
                    };

                    // Create offer
                    const offer = await this.peerConnection.createOffer();
                    await this.peerConnection.setLocalDescription(offer);

                    console.log('üì§ Sending SDP offer to OpenAI...');

                    // Send offer to OpenAI Realtime API
                    const baseUrl = 'https://api.openai.com/v1/realtime';
                    const model = 'gpt-4o-realtime-preview-2025-06-03';

                    const sdpResponse = await fetch(`${baseUrl}?model=${model}`, {
                        method: 'POST',
                        body: offer.sdp,
                        headers: {
                            'Authorization': `Bearer ${this.ephemeralKey}`,
                            'Content-Type': 'application/sdp'
                        },
                    });

                    if (!sdpResponse.ok) {
                        throw new Error(`OpenAI Realtime API error: ${sdpResponse.status} ${sdpResponse.statusText}`);
                    }

                    const answerSdp = await sdpResponse.text();
                    const answer = {
                        type: 'answer',
                        sdp: answerSdp,
                    };

                    await this.peerConnection.setRemoteDescription(answer);
                    console.log('‚úÖ WebRTC connection established with OpenAI');

                } catch (error) {
                    console.error('‚ùå WebRTC initialization error:', error);
                    throw error;
                }
            }

            setupDataChannelHandlers() {
                this.dataChannel.onopen = () => {
                    console.log('üì° Data channel opened');
                    this.dataChannelStatus.textContent = 'Open';
                };

                this.dataChannel.onclose = () => {
                    console.log('üì° Data channel closed');
                    this.dataChannelStatus.textContent = 'Closed';
                };

                this.dataChannel.onerror = (error) => {
                    console.error('üì° Data channel error:', error);
                    this.dataChannelStatus.textContent = 'Error';
                };

                this.dataChannel.onmessage = (event) => {
                    try {
                        const data = JSON.parse(event.data);
                        console.log('üì° Received data channel message:', data);
                        this.handleRealtimeEvent(data);
                    } catch (error) {
                        console.error('Error parsing data channel message:', error);
                    }
                };
            }

            sendTextToOpenAI(text) {
                if (this.dataChannel && this.dataChannel.readyState === 'open') {
                    // First, create the conversation item
                    const createMessage = {
                        type: 'conversation.item.create',
                        item: {
                            type: 'message',
                            role: 'user',
                            content: [
                                {
                                    type: 'input_text',
                                    text: text
                                }
                            ]
                        }
                    };
                    console.log('üì§ Creating conversation item:', text);
                    this.dataChannel.send(JSON.stringify(createMessage));

                    // Send user message to backend for tracking
                    this.sendRealtimeMessageToBackend('conversation.item.create', {
                        item: {
                            type: 'message',
                            role: 'user',
                            content: [
                                {
                                    type: 'input_text',
                                    text: text
                                }
                            ]
                        }
                    });

                    // Then, trigger a response
                    setTimeout(() => {
                        const responseMessage = {
                            type: 'response.create'
                        };
                        console.log('üì§ Triggering response creation');
                        this.dataChannel.send(JSON.stringify(responseMessage));
                    }, 100); // Small delay to ensure conversation item is created first
                } else {
                    console.error('Data channel not available for sending text');
                    this.showError('Connection not ready. Please try again.');
                }
            }

            setSystemPrompt(prompt) {
                if (this.dataChannel && this.dataChannel.readyState === 'open') {
                    const systemMessage = {
                        type: 'conversation.item.create',
                        item: {
                            type: 'message',
                            role: 'system',
                            content: [
                                {
                                    type: 'input_text',
                                    text: prompt
                                }
                            ]
                        }
                    };
                    console.log('üì§ Setting system prompt:', prompt);
                    this.dataChannel.send(JSON.stringify(systemMessage));
                } else {
                    console.error('Data channel not available for setting system prompt');
                    this.showError('Connection not ready. Please try again.');
                }
            }

            handleRealtimeEvent(event) {
                console.log('üì° Handling event:', event);

                switch (event.type) {
                    case 'conversation.item.delta':
                        // Handle conversation item updates
                        if (event.delta && event.delta.content) {
                            event.delta.content.forEach(contentItem => {
                                if (contentItem.type === 'text' && contentItem.text) {
                                    console.log('ü§ñ AI response text:', contentItem.text);
                                    this.showMessage(contentItem.text, 'ai');

                                    // Convert text to speech using our server
                                    this.convertTextToSpeech(contentItem.text);
                                }
                            });
                        }
                        break;

                    case 'response.delta':
                        // Handle response updates
                        if (event.delta && event.delta.content) {
                            event.delta.content.forEach(contentItem => {
                                if (contentItem.type === 'text' && contentItem.text) {
                                    console.log('ü§ñ AI response text:', contentItem.text);
                                    this.showMessage(contentItem.text, 'ai');

                                    // Convert text to speech using our server
                                    this.convertTextToSpeech(contentItem.text);
                                }
                            });
                        }
                        break;

                    case 'response.text.done':
                        // Handle completed text responses
                        if (event.text) {
                            console.log('ü§ñ AI response text:', event.text);
                            this.showMessage(event.text, 'ai');

                            // Convert text to speech using our server
                            this.convertTextToSpeech(event.text);

                            // Send to backend for meal completion tracking
                            this.sendRealtimeMessageToBackend('response.text.done', { text: event.text });
                        }
                        break;

                    case 'response.create':
                        console.log('üé§ AI started responding');
                        this.sendRealtimeMessageToBackend('response.create', {});
                        break;

                    case 'response.done':
                        console.log('üîá AI finished responding');
                        this.sendRealtimeMessageToBackend('response.done', {});
                        break;

                    case 'error':
                        console.error('‚ùå OpenAI Realtime error:', event.error);
                        console.error('‚ùå Full error details:', JSON.stringify(event, null, 2));
                        this.showError(`OpenAI error: ${event.error.message || event.error}`);
                        break;

                    default:
                        console.log('üì° Unknown event type:', event.type);
                }
            }

            sendRealtimeMessageToBackend(messageType, messageData) {
                try {
                    if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                        const realtimeMessage = {
                            type: 'realtime_message',
                            messageType: messageType,
                            messageData: messageData,
                            sessionId: this.sessionId,
                            timestamp: Date.now()
                        };

                        console.log('üì§ Sending realtime message to backend:', messageType);
                        this.websocket.send(JSON.stringify(realtimeMessage));
                    }
                } catch (error) {
                    console.error('‚ùå Error sending realtime message to backend:', error);
                }
            }

            startListening() {
                if (this.speechRecognition && !this.isListening) {
                    this.speechRecognition.start();
                }
            }

            stopListening() {
                if (this.speechRecognition && this.isListening) {
                    this.speechRecognition.stop();
                }
            }

            async convertTextToSpeech(text) {
                try {
                    console.log('üîä Converting text to speech:', text);

                    if (this.websocket && this.websocket.readyState === WebSocket.OPEN) {
                        // Send TTS request via WebSocket
                        this.websocket.send(JSON.stringify({
                            type: 'tts_request',
                            data: text,
                            sessionId: this.sessionId,
                        }));
                    } else {
                        throw new Error('WebSocket connection not available');
                    }

                } catch (error) {
                    console.error('‚ùå TTS conversion error:', error);
                    this.showError('Failed to convert text to speech: ' + error.message);
                }
            }

            handleRealtimeSessionResponse(message) {
                console.log('üîë Processing realtime session response:', message);
                try {
                    if (message.data && message.data.client_secret) {
                        this.realtimeSessionResponseReceived = true;
                        this.ephemeralKey = message.data.client_secret.value;
                        console.log('üîë Received ephemeral key for OpenAI Realtime API');
                        this.showMessage('Ephemeral key received. Ready to start call.', 'ai');
                        this.startCall();
                    } else {
                        console.error('‚ùå Realtime session response missing client_secret');
                        this.showError('Failed to receive ephemeral key from server');
                    }
                } catch (error) {
                    console.error('‚ùå Error processing realtime session response:', error);
                    this.showError('Error processing session response: ' + error.message);
                }
            }

            handleWebSocketMessage(message) {
                console.log('üì° Received WebSocket message:', message);

                switch (message.type) {
                    case 'realtime_session_response':
                        // This case should not be reached due to the above check
                        this.handleRealtimeSessionResponse(message);
                        break;

                    case 'audio':
                        // Handle audio response from our TTS service
                        if (message.data && message.data.audio) {
                            console.log('üîä Received audio data, length:', message.data.audio.length);
                            // Process audio asynchronously to prevent blocking
                            setTimeout(() => {
                                this.playAudio(message.data.audio);
                            }, 0);
                        } else {
                            console.error('‚ùå Audio message missing audio data');
                        }
                        break;

                    case 'tts_response':
                        // Handle TTS response (alternative format)
                        if (message.data && message.data.audio) {
                            console.log('üîä Received TTS audio data, length:', message.data.audio.length);
                            // Process audio asynchronously to prevent blocking
                            setTimeout(() => {
                                this.playAudio(message.data.audio);
                            }, 0);
                        }
                        break;

                    case 'error':
                        // Handle error messages
                        if (message.data && message.data.message) {
                            this.showError(message.data.message);
                        }
                        break;

                    case 'status':
                        // Handle status messages
                        if (message.data && message.data.message) {
                            console.log('üìä Status:', message.data.message);
                        }
                        break;

                    default:
                        console.log('üì° Unknown message type:', message.type);
                }
            }

            playAudio(audioData) {
                // Use requestIdleCallback or setTimeout to process audio without blocking
                const processAudio = () => {
                    try {
                        console.log('üîä Processing audio data, length:', audioData.length);

                        // Check if audio data is valid
                        if (!audioData || audioData.length < 100) {
                            console.error('‚ùå Audio data too short or invalid:', audioData);
                            return;
                        }

                        // Check if audio data is too large (over 1MB)
                        if (audioData.length > 1000000) {
                            console.warn('‚ö†Ô∏è Large audio data detected, processing may take time:', audioData.length, 'characters');
                        }

                        // Try to decode the base64 audio data
                        let audioBuffer;
                        try {
                            // Use a more efficient base64 decoding approach for large data
                            if (audioData.length > 500000) {
                                // For very large audio, process in chunks to avoid blocking
                                console.log('üîä Processing large audio data in chunks...');
                                audioBuffer = this.decodeBase64InChunks(audioData);
                            } else {
                                audioBuffer = Uint8Array.from(atob(audioData), c => c.charCodeAt(0));
                            }
                            console.log('üîä Decoded audio buffer, size:', audioBuffer.length, 'bytes');
                        } catch (decodeError) {
                            console.error('‚ùå Failed to decode base64 audio:', decodeError);
                            return;
                        }

                        // Create blob with appropriate MIME type
                        // Try different audio formats based on the data
                        let mimeType = 'audio/wav';
                        if (audioBuffer.length > 4) {
                            // Check for common audio format headers
                            const header = new Uint8Array(audioBuffer.slice(0, 4));
                            if (header[0] === 0xFF && header[1] === 0xFB) {
                                mimeType = 'audio/mpeg';
                            } else if (header[0] === 0x49 && header[1] === 0x44 && header[2] === 0x33) {
                                mimeType = 'audio/mp3';
                            } else if (header[0] === 0x52 && header[1] === 0x49 && header[2] === 0x46 && header[3] === 0x46) {
                                mimeType = 'audio/wav';
                            }
                        }

                        const blob = new Blob([audioBuffer], { type: mimeType });
                        const audioUrl = URL.createObjectURL(blob);

                        console.log('üîä Created audio blob, size:', blob.size, 'bytes, type:', mimeType);

                        const audio = new Audio(audioUrl);

                        audio.onloadstart = () => console.log('üîä Audio loading started');
                        audio.oncanplay = () => console.log('üîä Audio can play');
                        audio.onplay = () => console.log('üîä Audio started playing');
                        audio.onended = () => {
                            console.log('üîä Audio finished playing');
                            URL.revokeObjectURL(audioUrl);
                        };
                        audio.onerror = (error) => {
                            console.error('‚ùå Audio playback error:', error);
                            URL.revokeObjectURL(audioUrl);
                        };

                        audio.play().catch(error => {
                            console.error('‚ùå Error playing audio:', error);
                            URL.revokeObjectURL(audioUrl);
                        });

                    } catch (error) {
                        console.error('‚ùå Error processing audio:', error);
                    }
                };

                // Use requestIdleCallback if available, otherwise use setTimeout
                if (window.requestIdleCallback) {
                    requestIdleCallback(processAudio, { timeout: 1000 });
                } else {
                    setTimeout(processAudio, 0);
                }
            }

            decodeBase64InChunks(base64String) {
                // Decode large base64 strings in chunks to prevent blocking
                const chunkSize = 100000; // 100KB chunks
                const chunks = [];

                for (let i = 0; i < base64String.length; i += chunkSize) {
                    const chunk = base64String.slice(i, i + chunkSize);
                    const decodedChunk = Uint8Array.from(atob(chunk), c => c.charCodeAt(0));
                    chunks.push(decodedChunk);
                }

                // Combine all chunks
                const totalLength = chunks.reduce((sum, chunk) => sum + chunk.length, 0);
                const result = new Uint8Array(totalLength);
                let offset = 0;

                for (const chunk of chunks) {
                    result.set(chunk, offset);
                    offset += chunk.length;
                }

                return result;
            }

            endCall() {
                console.log('üì¥ Ending call');
                this.isInCall = false;
                this.startCallBtn.disabled = false;
                this.endCallBtn.disabled = true;
                this.updateCallStatus('Call ended');
                this.recordingIndicator.style.display = 'none';
                this.speechControls.style.display = 'none';
                this.ssmlTestSection.style.display = 'none';

                // Stop speech recognition if active
                if (this.isListening) {
                    this.stopListening();
                }

                // Clean up WebRTC
                if (this.dataChannel) {
                    this.dataChannel.close();
                    this.dataChannel = null;
                }

                if (this.peerConnection) {
                    this.peerConnection.close();
                    this.peerConnection = null;
                }

                // Reset status
                this.webrtcConnectionStatus.textContent = 'Disconnected';
                this.dataChannelStatus.textContent = 'Closed';
                this.speechStatus.textContent = 'Not Active';

                this.showMessage('Call ended', 'user');
            }

            disconnect() {
                if (this.isInCall) {
                    this.endCall();
                }

                // Close WebSocket connection
                if (this.websocket) {
                    this.websocket.close();
                    this.websocket = null;
                }

                this.isConnected = false;
                this.sessionId = null;
                this.userId = null;
                this.userEmail = null;
                this.ephemeralKey = null;

                // Reset realtime session tracking
                this.realtimeSessionRequestSent = false;
                this.realtimeSessionResponseReceived = false;
                this.realtimeSessionRetryCount = 0;

                this.updateStatus('disconnected', 'Disconnected');
                this.connectBtn.disabled = false;
                this.disconnectBtn.disabled = true;
                this.startCallBtn.disabled = true;
                this.endCallBtn.disabled = true;
                this.sessionInfo.style.display = 'none';
                this.callStatus.style.display = 'none';
                this.webrtcStatus.style.display = 'none';
                this.speechControls.style.display = 'none';
                this.ssmlTestSection.style.display = 'none';
                this.recordingIndicator.style.display = 'none';

                this.showMessage('Disconnected', 'ai');
            }

            testSSML() {
                const ssmlText = this.ssmlTestTextArea.value.trim();
                if (!ssmlText) {
                    this.showError('Please enter SSML text to test.');
                    return;
                }

                this.showMessage(`Testing SSML: ${ssmlText}`, 'ai');
                this.convertTextToSpeech(ssmlText);
            }

            clearSSML() {
                this.ssmlTestTextArea.value = '';
                this.showMessage('SSML text area cleared.', 'ai');
            }
        }

        // Initialize the client when the page loads
        let client;
        document.addEventListener('DOMContentLoaded', () => {
            client = new OpenAIRealtimeClient();
            // Make client globally accessible for console debugging
            window.client = client;
        });
    </script>

    <style>
        .webrtc-status {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
        }

        .status-item {
            display: flex;
            justify-content: space-between;
            margin-bottom: 8px;
            font-size: 14px;
        }

        .status-item:last-child {
            margin-bottom: 0;
        }

        .status-item span:first-child {
            font-weight: 500;
            color: #495057;
        }

        .status-item span:last-child {
            font-weight: 600;
            color: #007bff;
        }

        .speech-controls {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            text-align: center;
        }

        .speech-status {
            margin-bottom: 10px;
            font-size: 14px;
            font-weight: 500;
        }

        .speech-status span:last-child {
            font-weight: 600;
            color: #28a745;
        }

        .btn-success {
            background-color: #28a745;
            border-color: #28a745;
            color: white;
        }

        .btn-success:hover {
            background-color: #218838;
            border-color: #1e7e34;
        }

        .btn-warning {
            background-color: #ffc107;
            border-color: #ffc107;
            color: #212529;
        }

        .btn-warning:hover {
            background-color: #e0a800;
            border-color: #d39e00;
        }

        .btn-info {
            background-color: #17a2b8;
            border-color: #17a2b8;
            color: white;
        }

        .btn-info:hover {
            background-color: #138496;
            border-color: #117a8b;
        }

        .btn-outline-secondary {
            background-color: transparent;
            border-color: #6c757d;
            color: #6c757d;
        }

        .btn-outline-secondary:hover {
            background-color: #6c757d;
            border-color: #6c757d;
            color: white;
        }

        .ssml-test-section {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
            font-size: 14px;
            color: #343a40;
        }

        .ssml-test-section h3 {
            margin-top: 0;
            margin-bottom: 10px;
            color: #007bff;
        }

        .ssml-test-section p {
            margin-bottom: 15px;
        }

        .ssml-test-controls {
            display: flex;
            flex-direction: column;
            gap: 10px;
            margin-bottom: 15px;
        }

        .ssml-textarea {
            width: 100%;
            padding: 10px;
            border: 1px solid #ced4da;
            border-radius: 4px;
            font-family: monospace;
            font-size: 13px;
            line-height: 1.5;
            white-space: pre-wrap;
            word-break: break-all;
            min-height: 100px;
            resize: vertical;
        }

        .ssml-test-buttons {
            display: flex;
            gap: 10px;
            justify-content: flex-end;
        }

        .ssml-examples {
            margin-top: 20px;
            padding-top: 15px;
            border-top: 1px dashed #e9ecef;
        }

        .ssml-examples details {
            border: 1px solid #e9ecef;
            border-radius: 4px;
            padding: 10px;
            background-color: #f1f3f5;
        }

        .ssml-examples summary {
            cursor: pointer;
            font-weight: 600;
            color: #007bff;
        }

        .ssml-examples summary:hover {
            color: #0056b3;
        }

        .ssml-examples div {
            margin-top: 10px;
            padding-left: 20px;
        }

        .ssml-examples code {
            background-color: #e9ecef;
            padding: 2px 4px;
            border-radius: 3px;
            font-size: 0.9em;
        }

        .example-item {
            margin-bottom: 8px;
        }

        .example-item strong {
            color: #343a40;
        }

        .example-item code {
            font-size: 0.9em;
            background-color: #f8f9fa;
            padding: 2px 4px;
            border-radius: 3px;
        }
    </style>
</body>

</html>