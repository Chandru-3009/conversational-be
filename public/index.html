<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Nutrina Voice Agent Test</title>
    <link rel="stylesheet" href="style.css">
    <!-- VAD Library Dependencies -->
    <script src="https://cdn.jsdelivr.net/npm/onnxruntime-web@1.14.0/dist/ort.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@ricky0123/vad-web@0.0.22/dist/bundle.min.js"></script>
</head>

<body>
    <div class="container">
        <div class="header">
            <h1>Nutrina Voice Agent</h1>
            <p>Call your voice assistant - just like a phone call!</p>
        </div>

        <div id="status" class="status disconnected">
            Disconnected
        </div>

        <div id="userEmailSection" class="user-email-section">
            <label for="userEmail">Email Address *</label>
            <input type="email" id="userEmail" placeholder="Enter your email address" class="email-input" required>
            <small>Required for personalized experience and data tracking</small>
        </div>

        <div id="sessionInfo" class="session-info" style="display: none;">
            Session ID: <span id="sessionId"></span>
        </div>

        <div id="error" class="error" style="display: none;"></div>
        <div id="success" class="success" style="display: none;"></div>

        <div class="controls">
            <button id="connectBtn" class="btn btn-primary">üìû Connect</button>
            <button id="disconnectBtn" class="btn btn-secondary" disabled>üö´ Disconnect</button>
            <button id="monitorToggleBtn" class="btn btn-small" disabled>üîä Monitor: OFF</button>
            <button id="previewToggleBtn" class="btn btn-small" disabled>üéµ Preview: ON</button>
            <button id="pcmToggleBtn" class="btn btn-small" disabled>üé§ PCM: OFF</button>
            <button id="webSpeechToggleBtn" class="btn btn-small" disabled>üó£Ô∏è Web Speech: ON</button>
            <button id="testWsBtn" class="btn btn-small" disabled>üß™ Test WS</button>
        </div>

        <div id="callStatus" class="call-status" style="display: none;">
            Ready to call
        </div>

        <div id="transcriptionMode" class="transcription-mode" style="display: none;">
            <span>üé§ Transcription: </span>
            <span id="transcriptionModeValue">Web Speech API</span>
        </div>

        <div id="recordingIndicator" class="recording-indicator">
            <div class="recording-dot"></div>
            <span>Listening...</span>
        </div>

        <div id="silenceIndicator" class="silence-indicator">
            <div class="silence-dot"></div>
            <span>Waiting for silence (3s)...</span>
        </div>

        <div id="audioPreview" class="audio-preview" style="display: none;">
            <div class="preview-header">
                <span>üéµ Audio Preview</span>
                <button id="retryRecordingBtn" class="btn btn-small">üîÑ Retry</button>
            </div>
            <div class="preview-controls">
                <button id="playAudioBtn" class="btn btn-small">‚ñ∂Ô∏è Play</button>
                <button id="pauseAudioBtn" class="btn btn-small" disabled>‚è∏Ô∏è Pause</button>
                <span id="audioDuration">0:00</span>
            </div>
            <div class="preview-actions">
                <button id="sendAudioBtn" class="btn btn-primary">üì§ Send Audio</button>
                <button id="cancelAudioBtn" class="btn btn-secondary">‚ùå Cancel</button>
            </div>
        </div>

        <div class="audio-visualizer" id="audioVisualizer">
            <div class="audio-bars" id="audioBars">
                <!-- Audio bars will be generated here -->
            </div>
            <div class="audio-level-meter">
                <span>Mic Level: </span>
                <span id="audioLevelValue">0%</span>
            </div>
        </div>

        <div class="conversation" id="conversation">
            <div class="message ai">
                <div>Welcome! Click "Connect" and then the call button to start chatting with your voice assistant.
                </div>
                <div class="message-time">System</div>
            </div>
        </div>
    </div>

    <script>
        // RECOMMENDED ALTERNATIVES FOR PRODUCTION:
        // 1. Use MediaRecorder API with WebM/Opus for better quality
        // 2. Consider libraries like:
        //    - RecordRTC (https://github.com/muaz-khan/RecordRTC)
        //    - MediaRecorder.js (https://github.com/addy-dclxvi/MediaRecorder.js)
        //    - Web Audio API with AudioWorklet for real-time processing
        // 3. For silence detection: Use Web Audio API's AudioContext with analyser node
        // 4. For audio processing: Use AudioWorklet or WebAssembly-based solutions

        class VoiceAgentClient {
            constructor() {
                this.ws = null;
                this.audioContext = null;
                this.analyser = null;
                this.scriptProcessor = null;
                this.isRecording = false;
                this.isInCall = false;
                this.userTurn = true; // Track whose turn it is (true = user's turn)
                this.sessionId = null;
                this.audioChunks = [];
                this.audioBars = [];

                // VAD properties
                this.vad = null;
                this.isVADInitialized = false;
                this.silenceThreshold = 1000; // 1 second silence threshold for faster response
                this.speechStartTime = null;
                this.minSpeechDuration = 500; // 500ms minimum speech duration for faster response
                this.silenceTimeout = null; // Timer for silence threshold
                this.countdownInterval = null; // Timer for countdown display

                // Streaming properties
                this.isStreaming = false; // Track if we're currently streaming
                this.streamingChunks = []; // Store chunks for streaming
                this.lastStreamTime = 0; // Track last stream time
                this.streamInterval = null; // Interval for streaming chunks

                // Store the audio stream for reuse
                this.audioStream = null;

                // PCM audio properties
                this.sampleRate = 48000; // Higher sample rate for better quality
                this.targetSampleRate = 16000; // Target for Google STT
                this.channelCount = 1; // Mono
                this.bufferSize = 4096; // Buffer size for ScriptProcessorNode

                // Direct PCM capture properties
                this.pcmAudioContext = null;
                this.pcmScriptProcessor = null;
                this.pcmChunks = [];
                this.isPcmCapturing = false;
                this.pcmMode = false; // Default to WebM mode for better performance with ElevenLabs STT

                // Audio preview properties
                this.recordedAudioBlob = null;
                this.audioPreviewElement = null;
                this.isPreviewMode = false; // Default to preview mode

                // Raw audio data for direct PCM conversion
                this.rawAudioData = [];

                // Recording timing properties
                this.mediaRecorderStartTime = null;
                this.minRecordingDuration = 1500; // 1.5 seconds minimum

                // Real-time playback properties
                this.monitorGain = null;
                this.monitoringEnabled = false;

                // Web Speech API properties
                this.webSpeechRecognition = null;
                this.webSpeechEnabled = true; // Default to ON
                this.isWebSpeechListening = false;
                this.webSpeechSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;

                this.initializeElements();
                this.setupEventListeners();
                this.createAudioBars();
            }

            initializeElements() {
                this.statusEl = document.getElementById('status');
                this.connectBtn = document.getElementById('connectBtn');
                this.disconnectBtn = document.getElementById('disconnectBtn');
                this.monitorToggleBtn = document.getElementById('monitorToggleBtn');
                this.previewToggleBtn = document.getElementById('previewToggleBtn');
                this.pcmToggleBtn = document.getElementById('pcmToggleBtn');
                this.webSpeechToggleBtn = document.getElementById('webSpeechToggleBtn');
                this.testWsBtn = document.getElementById('testWsBtn');
                this.callStatus = document.getElementById('callStatus');
                this.recordingIndicator = document.getElementById('recordingIndicator');
                this.silenceIndicator = document.getElementById('silenceIndicator');
                this.conversation = document.getElementById('conversation');
                this.sessionInfo = document.getElementById('sessionInfo');
                this.sessionIdSpan = document.getElementById('sessionId');
                this.errorEl = document.getElementById('error');
                this.successEl = document.getElementById('success');
                this.audioVisualizer = document.getElementById('audioVisualizer');
                this.audioBarsContainer = document.getElementById('audioBars');
                this.audioLevelValue = document.getElementById('audioLevelValue');

                // User email element
                this.userEmailInput = document.getElementById('userEmail');

                // Transcription mode elements
                this.transcriptionMode = document.getElementById('transcriptionMode');
                this.transcriptionModeValue = document.getElementById('transcriptionModeValue');

                // Audio preview elements
                this.audioPreview = document.getElementById('audioPreview');
                this.playAudioBtn = document.getElementById('playAudioBtn');
                this.pauseAudioBtn = document.getElementById('pauseAudioBtn');
                this.sendAudioBtn = document.getElementById('sendAudioBtn');
                this.cancelAudioBtn = document.getElementById('cancelAudioBtn');
                this.retryRecordingBtn = document.getElementById('retryRecordingBtn');
                this.audioDuration = document.getElementById('audioDuration');
            }

            createAudioBars() {
                for (let i = 0; i < 20; i++) {
                    const bar = document.createElement('div');
                    bar.className = 'audio-bar';
                    bar.style.height = '10px';
                    this.audioBars.push(bar);
                    this.audioBarsContainer.appendChild(bar);
                }
            }

            setupEventListeners() {
                this.connectBtn.addEventListener('click', () => this.connect());
                this.disconnectBtn.addEventListener('click', () => this.disconnect());
                this.monitorToggleBtn.addEventListener('click', () => this.toggleMonitoring());
                this.previewToggleBtn.addEventListener('click', () => this.togglePreview());
                this.pcmToggleBtn.addEventListener('click', () => this.togglePcmCapture());
                this.webSpeechToggleBtn.addEventListener('click', () => this.toggleWebSpeech());
                this.testWsBtn.addEventListener('click', () => this.testWebSocketConnection());

                // Audio preview event listeners
                this.playAudioBtn.addEventListener('click', () => this.playRecordedAudio());
                this.pauseAudioBtn.addEventListener('click', () => this.pauseRecordedAudio());
                this.sendAudioBtn.addEventListener('click', () => this.sendRecordedAudio());
                this.cancelAudioBtn.addEventListener('click', () => this.cancelAudioPreview());
                this.retryRecordingBtn.addEventListener('click', () => this.retryRecording());
            }

            // VAD initialization method commented out since we're using Web Speech API
            /*
            async initializeVAD() {
                try {
                    console.log('Initializing VAD...');
                    this.vad = await vad.MicVAD.new({
                        onSpeechStart: () => {
                            console.log('VAD: Speech start detected');
                            this.handleSpeechStart();
                        },
                        onSpeechEnd: (audio) => {
                            console.log('VAD: Speech end detected, audio length:', audio.length);
                            this.handleSpeechEnd(audio);
                        },
                        onVADMisfire: () => {
                            console.log('VAD: Misfire detected');
                        },
                        // VAD Configuration optimized for better speech detection
                        silenceThreshold: this.silenceThreshold, // Wait 1 second of silence before processing
                        speechThreshold: 200,   // Require 200ms of speech before triggering (reduced for better detection)
                        preSpeechPadFrames: 20, // Include 20 frames (400ms) before speech detection (increased for better capture)
                        minSpeechFrames: 1,     // Minimum 1 frame (20ms) of speech required (reduced for better detection)
                        maxSilenceFrames: 80,   // Maximum 80 frames (1.6 seconds) of silence allowed
                        frameSamples: 1024,     // Frame size for processing
                        positiveSpeechThreshold: 0.2,  // Lower threshold for better speech detection
                        negativeSpeechThreshold: 0.2,  // Lower threshold for better silence detection
                        redemptionFrames: 15    // Allow 15 frames of redemption before final decision (increased for stability)
                    });
                    this.isVADInitialized = true;
                    console.log('VAD initialized successfully with improved configuration');
                } catch (error) {
                    console.error('Failed to initialize VAD:', error);
                    this.showError('Failed to initialize voice activity detection: ' + error.message);
                }
            }
            */

            // VAD speech handling methods commented out since we're using Web Speech API
            /*
            handleSpeechStart() {
                if (!this.isInCall || !this.userTurn) {
                    console.log('VAD speech start ignored - not in call or not user turn');
                    return;
                }

                // If we were waiting for silence threshold, cancel it
                if (this.silenceTimeout) {
                    console.log('VAD: New speech detected, canceling silence timeout');
                    clearTimeout(this.silenceTimeout);
                    this.silenceTimeout = null;
                }

                // Clear countdown interval if it exists
                if (this.countdownInterval) {
                    clearInterval(this.countdownInterval);
                    this.countdownInterval = null;
                }

                console.log('VAD: Starting recording due to speech detection');
                this.speechStartTime = Date.now();
                this.recordingIndicator.style.display = 'flex';
                this.silenceIndicator.style.display = 'none';

                // Start PCM capture for new speech segment
                if (this.pcmMode) {
                    if (!this.isPcmCapturing) {
                        this.startPcmCapture();
                    }
                } else {
                    // For WebM mode, start MediaRecorder and clear previous chunks
                    if (!this.mediaRecorder || this.mediaRecorder.state === 'inactive') {
                        console.log('VAD: Creating new MediaRecorder for speech segment');
                        this.createMediaRecorder();
                    }

                    // Clear previous audio chunks for new speech segment
                    this.audioChunks = [];
                    this.streamingChunks = [];

                    // Start MediaRecorder for the new speech segment
                    if (this.mediaRecorder.state === 'inactive') {
                        console.log('VAD: Starting MediaRecorder for new speech segment');
                        this.mediaRecorder.start(100); // Emit data every 100ms
                        this.isRecording = true;
                    }
                }

                // Send speech start signal to reset server processing state
                this.sendSpeechStartSignal();
            }
            */

            /*
            handleSpeechEnd(audio) {
                if (!this.isInCall || !this.userTurn) {
                    console.log('VAD speech end ignored - not in call or not user turn');
                    return;
                }

                const speechDuration = Date.now() - this.speechStartTime;
                console.log('VAD: Speech ended, duration:', speechDuration, 'ms');

                // Check if speech duration meets minimum requirement
                if (speechDuration < this.minSpeechDuration) {
                    console.log('VAD: Speech too short, ignoring');
                    this.speechStartTime = null;
                    this.recordingIndicator.style.display = 'none';
                    return;
                }

                // Instead of immediately stopping, wait for silence threshold
                console.log('VAD: Waiting for silence threshold before processing...');
                this.silenceIndicator.style.display = 'flex';
                this.recordingIndicator.style.display = 'none';

                // Update the silence indicator text
                const silenceIndicatorText = this.silenceIndicator.querySelector('span');
                silenceIndicatorText.textContent = 'Waiting for silence (1s)...';

                // Clear any existing silence timeout
                if (this.silenceTimeout) {
                    clearTimeout(this.silenceTimeout);
                }

                // Wait for 1 second of silence before processing
                this.silenceTimeout = setTimeout(() => {
                    console.log('VAD: Silence threshold reached, processing audio');
                    silenceIndicatorText.textContent = 'Processing your message...';

                    if (this.pcmMode) {
                        // Stop PCM capture and send PCM data
                        this.stopPcmCapture();
                        this.sendPcmDataToServer();
                    } else {
                        // Stop MediaRecorder and send complete WebM audio
                        if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                            console.log('VAD: Stopping MediaRecorder after silence threshold');
                            this.mediaRecorder.stop();
                            this.isRecording = false;
                        } else {
                            // If MediaRecorder is not recording, send existing chunks
                            if (this.audioChunks.length > 0) {
                                console.log('VAD: Sending existing audio chunks');
                                const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                                this.recordedAudioBlob = audioBlob;

                                if (this.isPreviewMode) {
                                    this.createAudioPreviewFromBlobs();
                                } else {
                                    console.log('Preview mode off - auto-sending audio');
                                    this.sendWebmBlobToServer(audioBlob);
                                }
                            }
                        }
                    }

                    this.speechStartTime = null;
                    this.silenceIndicator.style.display = 'none';
                    this.silenceTimeout = null;
                }, this.silenceThreshold); // 1 second silence threshold

                // Show countdown
                let countdown = 1;
                const countdownInterval = setInterval(() => {
                    countdown--;
                    if (countdown > 0) {
                        silenceIndicatorText.textContent = `Waiting for silence (${countdown}s)...`;
                    } else {
                        clearInterval(countdownInterval);
                    }
                }, 1000);

                // Store the countdown interval for cleanup
                this.countdownInterval = countdownInterval;
            }
            */

            generateSessionId() {
                return 'session_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
            }

            updateStatus(status, message) {
                this.statusEl.className = `status ${status}`;
                this.statusEl.textContent = message;
            }

            updateCallStatus(message) {
                this.callStatus.textContent = message;
            }

            updateTurnIndicator() {
                if (this.isInCall) {
                    if (this.userTurn) {
                        this.updateCallStatus('üé§ Your turn to speak');
                    } else {
                        this.updateCallStatus('ü§ñ AI is responding...');
                    }
                } else {
                    this.updateCallStatus('Ready to call');
                }
            }

            showMessage(content, type = 'ai', timestamp = new Date()) {
                const messageDiv = document.createElement('div');
                messageDiv.className = `message ${type}`;

                const contentDiv = document.createElement('div');
                contentDiv.textContent = content;

                const timeDiv = document.createElement('div');
                timeDiv.className = 'message-time';
                timeDiv.textContent = timestamp.toLocaleTimeString();

                messageDiv.appendChild(contentDiv);
                messageDiv.appendChild(timeDiv);

                this.conversation.appendChild(messageDiv);
                this.conversation.scrollTop = this.conversation.scrollHeight;
            }

            showError(message) {
                this.errorEl.textContent = message;
                this.errorEl.style.display = 'block';
                setTimeout(() => {
                    this.errorEl.style.display = 'none';
                }, 5000);
            }

            showSuccess(message) {
                this.successEl.textContent = message;
                this.successEl.style.display = 'block';
                setTimeout(() => {
                    this.successEl.style.display = 'none';
                }, 3000);
            }

            async connect() {
                try {
                    // Validate email is provided
                    const userEmail = this.userEmailInput.value.trim();
                    if (!userEmail) {
                        this.showError('Email address is required to connect.');
                        return;
                    }

                    // Basic email validation
                    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
                    if (!emailRegex.test(userEmail)) {
                        this.showError('Please enter a valid email address.');
                        return;
                    }

                    this.sessionId = this.generateSessionId();

                    const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                    let wsUrl = '';
                    if (!window.location.host || window.location.host.includes('D:/')) {
                        wsUrl = `ws://localhost:3031/ws?sessionId=${this.sessionId}&userEmail=${encodeURIComponent(userEmail)}`;
                    } else {
                        wsUrl = `${protocol}//${window.location.host}/ws?sessionId=${this.sessionId}&userEmail=${encodeURIComponent(userEmail)}`;
                    }


                    this.updateStatus('connecting', 'Connecting...');
                    this.connectBtn.disabled = true;

                    // Request microphone access once during connection
                    console.log('Requesting microphone access during connection...');
                    this.audioStream = await navigator.mediaDevices.getUserMedia({
                        audio: {
                            sampleRate: 48000, // Higher sample rate for better quality
                            channelCount: 1,
                            echoCancellation: false, // Disable echo cancellation for better speech quality
                            noiseSuppression: false, // Disable noise suppression for better speech quality
                            autoGainControl: false, // Disable auto gain control for consistent levels
                            latency: 0.01, // Low latency
                            volume: 1.0
                        }
                    });
                    console.log('Microphone access granted during connection');

                    // VAD initialization commented out since we're using Web Speech API
                    // await this.initializeVAD();

                    // Check Web Speech API support (but don't initialize yet)
                    this.webSpeechSupported = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;

                    // Update button text based on support
                    if (!this.webSpeechSupported) {
                        this.webSpeechToggleBtn.textContent = 'üó£Ô∏è Web Speech: NOT SUPPORTED';
                        this.webSpeechToggleBtn.disabled = true;
                        console.warn('Web Speech API not supported in this browser, falling back to VAD');
                    } else {
                        console.log('‚úÖ Web Speech API is supported in this browser');
                    }

                    this.ws = new WebSocket(wsUrl);

                    this.ws.onopen = () => {
                        this.updateStatus('connected', 'Connected');
                        this.connectBtn.disabled = true;
                        this.disconnectBtn.disabled = false;
                        this.monitorToggleBtn.disabled = false;
                        this.previewToggleBtn.disabled = false;
                        this.pcmToggleBtn.disabled = false;
                        this.webSpeechToggleBtn.disabled = false;
                        this.webSpeechToggleBtn.textContent = `üó£Ô∏è Web Speech: ${this.webSpeechEnabled ? 'ON' : 'OFF'}`;
                        this.testWsBtn.disabled = false;
                        this.sessionInfo.style.display = 'block';
                        this.sessionIdSpan.textContent = this.sessionId;
                        this.callStatus.style.display = 'block';
                        this.transcriptionMode.style.display = 'flex';
                        this.updateTranscriptionModeDisplay();
                        this.showSuccess(`Connected with email: ${userEmail}`);

                        // Automatically start the call after connection
                        setTimeout(() => {
                            this.startCall();
                        }, 1000);
                    };

                    this.ws.onmessage = (event) => {
                        try {
                            const data = JSON.parse(event.data);
                            this.handleWebSocketMessage(data);
                        } catch (error) {
                            console.error('Error parsing WebSocket message:', error);
                        }
                    };

                    this.ws.onclose = () => {
                        this.updateStatus('disconnected', 'Disconnected');
                        this.connectBtn.disabled = false;
                        this.disconnectBtn.disabled = true;
                        this.monitorToggleBtn.disabled = true;
                        this.previewToggleBtn.disabled = true;
                        this.pcmToggleBtn.disabled = true;
                        this.webSpeechToggleBtn.disabled = true;
                        this.testWsBtn.disabled = true;
                        this.sessionInfo.style.display = 'none';
                        this.callStatus.style.display = 'none';
                        this.transcriptionMode.style.display = 'none';
                        this.isInCall = false;
                        this.isRecording = false;
                        this.recordingIndicator.style.display = 'none';
                        this.silenceIndicator.style.display = 'none';
                        // Clean up audio stream
                        if (this.audioStream) {
                            this.audioStream.getTracks().forEach(track => track.stop());
                            this.audioStream = null;
                        }
                        // Stop VAD
                        if (this.vad) {
                            this.vad.destroy();
                            this.vad = null;
                            this.isVADInitialized = false;
                        }
                        this.showMessage('Connection closed', 'ai');
                    };

                    this.ws.onerror = (error) => {
                        console.error('WebSocket error:', error);
                        this.showError('Connection failed. Make sure the server is running.');
                    };

                } catch (error) {
                    console.error('Connection error:', error);
                    this.showError('Failed to connect: ' + error.message);
                    this.updateStatus('disconnected', 'Connection failed');
                    this.connectBtn.disabled = false;
                    // Clean up audio stream if connection fails
                    if (this.audioStream) {
                        this.audioStream.getTracks().forEach(track => track.stop());
                        this.audioStream = null;
                    }
                }
            }

            handleWebSocketMessage(data) {
                switch (data.type) {
                    case 'audio':
                        this.handleAudioResponse(data);
                        break;
                    case 'status':
                        this.showMessage(data.data.message, 'ai');
                        break;
                    case 'error':
                        this.showError(data.data.message);
                        break;
                    default:
                        console.log('Unknown message type:', data.type);
                }
            }

            handleAudioResponse(data) {
                console.log('Received audio response from server:', data);
                if (data.data.text) {
                    console.log('AI response text:', data.data.text);
                    this.showMessage(data.data.text, 'ai');
                }

                if (data.data.audio) {
                    console.log('AI response contains audio data');
                    this.playAudio(data.data.audio);
                }

                // After AI responds, switch back to user's turn
                if (this.isInCall) {
                    this.userTurn = true;
                    console.log('Switched back to user\'s turn');
                    this.updateTurnIndicator();
                    this.showMessage('Your turn to speak...', 'ai');

                    // Web Speech API should already be running, no need to restart
                    // The onresult handler will filter based on userTurn
                    console.log('Web Speech API should already be listening for user input');
                } else {
                    console.log('Call ended, not switching turns');
                }
            }

            playAudio(audioData) {
                try {
                    const audioBuffer = Uint8Array.from(atob(audioData), c => c.charCodeAt(0));
                    const blob = new Blob([audioBuffer], { type: 'audio/wav' });
                    const audioUrl = URL.createObjectURL(blob);

                    const audio = new Audio(audioUrl);
                    audio.play().catch(error => {
                        console.error('Error playing audio:', error);
                    });

                    audio.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                    };
                } catch (error) {
                    console.error('Error processing audio:', error);
                }
            }

            toggleCall() {
                if (!this.isInCall) {
                    this.startCall();
                } else {
                    this.endCall();
                }
            }

            async startCall() {
                try {
                    this.isInCall = true;
                    this.userTurn = true; // Start with user's turn
                    this.updateCallStatus('Call in progress...');
                    this.updateTurnIndicator();
                    this.showMessage('Call started - it\'s your turn to speak!', 'user');

                    await this.startListening();

                } catch (error) {
                    console.error('Error starting call:', error);
                    this.showError('Failed to start call: ' + error.message);
                    this.endCall();
                }
            }

            endCall() {
                console.log('Ending call, isInCall:', this.isInCall, 'isRecording:', this.isRecording);
                this.isInCall = false;
                this.isRecording = false;
                this.userTurn = false; // Reset turn state
                this.updateCallStatus('Call ended');
                this.recordingIndicator.style.display = 'none';
                this.silenceIndicator.style.display = 'none';
                // this.stopAudioVisualization(); // Commented out since method is disabled

                // Clear silence timeout
                if (this.silenceTimeout) {
                    clearTimeout(this.silenceTimeout);
                    this.silenceTimeout = null;
                }

                // Clear countdown interval
                if (this.countdownInterval) {
                    clearInterval(this.countdownInterval);
                    this.countdownInterval = null;
                }

                // Hide audio preview if it's showing
                if (this.isPreviewMode) {
                    this.hideAudioPreview();
                }

                // Stop MediaRecorder if it's still active
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    console.log('Stopping MediaRecorder on call end');
                    this.mediaRecorder.stop();
                }

                // VAD is disabled, no need to stop it
                // if (this.vad && this.isVADInitialized) {
                //     console.log('Stopping VAD listening on call end');
                //     this.isVADInitialized = false;
                // }

                // Stop Web Speech API
                if (this.isWebSpeechListening) {
                    console.log('Stopping Web Speech API on call end');
                    this.stopWebSpeechRecognition();
                }

                // Clean up real-time playback
                if (this.monitorGain) {
                    console.log('Disconnecting real-time playback on call end');
                    this.monitorGain.disconnect();
                    this.monitorGain = null;
                }

                // Stop microphone if it's still active (legacy ScriptProcessor)
                if (this.scriptProcessor) {
                    this.stopMicrophone();
                }

                this.showMessage('Call ended', 'user');
            }

            async startListening() {
                if (!this.isInCall) {
                    console.log('Not in call, skipping startListening');
                    return;
                }
                if (!this.userTurn) {
                    console.log('Not user\'s turn, skipping startListening');
                    return;
                }
                if (!this.audioStream) {
                    console.error('No audio stream available');
                    this.showError('Microphone access not available. Please reconnect.');
                    return;
                }

                try {
                    // Check if Web Speech API is enabled and supported
                    if (this.webSpeechEnabled && this.webSpeechSupported) {
                        console.log('üó£Ô∏è Using Web Speech API for listening');

                        // Only start if not already listening
                        if (!this.isWebSpeechListening) {
                            this.startWebSpeechRecognition();
                        } else {
                            console.log('üó£Ô∏è Web Speech API already listening, no need to restart');
                        }
                        return;
                    }

                    // Fallback to VAD if Web Speech API is disabled or not supported
                    // VAD fallback commented out since we're using Web Speech API as primary method
                    /*
                    if (!this.isVADInitialized || !this.vad) {
                        console.error('VAD not initialized');
                        this.showError('Voice activity detection not available. Please reconnect.');
                        return;
                    }

                    // Stop Web Speech API if it's running to avoid conflicts
                    if (this.isWebSpeechListening) {
                        console.log('üõë Stopping Web Speech API to use VAD');
                        this.stopWebSpeechRecognition();
                    }

                    // Real-time monitoring for audio visualization
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    const source = this.audioContext.createMediaStreamSource(this.audioStream);
                    this.monitorGain = this.audioContext.createGain();
                    this.monitorGain.gain.value = this.monitoringEnabled ? 0.3 : 0;
                    source.connect(this.monitorGain);
                    this.monitorGain.connect(this.audioContext.destination);

                    // Only start MediaRecorder if not in PCM mode
                    if (!this.pcmMode) {
                        // MediaRecorder will be created when speech starts
                        console.log('WebM mode enabled - MediaRecorder will be created on speech start');
                    } else {
                        console.log('PCM mode enabled - skipping MediaRecorder initialization');
                    }

                    this.recordingIndicator.style.display = 'none';
                    this.silenceIndicator.style.display = 'none';

                    // Start VAD listening
                    console.log('Starting VAD listening...');
                    await this.vad.start();
                    console.log('VAD listening started');

                    // Start audio level monitoring for visualization
                    this.startAudioLevelMonitoring(this.audioStream);
                    */

                    // Since VAD is disabled, show error if Web Speech API is not available
                    if (!this.webSpeechSupported) {
                        this.showError('Web Speech API not supported and VAD is disabled. Please enable Web Speech API support.');
                        return;
                    }

                } catch (error) {
                    console.error('Error starting listening:', error);
                    this.showError('Failed to start listening: ' + error.message);
                    this.endCall();
                }
            }

            stopRecording() {
                if (this.mediaRecorder && this.mediaRecorder.state === 'recording') {
                    console.log('Stopping MediaRecorder');
                    this.mediaRecorder.stop();
                }

                // VAD is disabled, no need to stop it
                // if (this.vad && this.isVADInitialized) {
                //     console.log('Stopping VAD listening');
                //     this.isVADInitialized = false;
                // }

                // Clean up real-time playback
                if (this.monitorGain) {
                    console.log('Disconnecting real-time playback');
                    this.monitorGain.disconnect();
                    this.monitorGain = null;
                }

                if (this.recordingTimeout) {
                    clearTimeout(this.recordingTimeout);
                    this.recordingTimeout = null;
                }

                this.isRecording = false;
                this.recordingIndicator.style.display = 'none';
                this.stopAudioVisualization();
            }

            createAudioPreviewFromBlobs() {
                if (this.audioChunks.length === 0) {
                    console.log('No audio chunks to preview');
                    return;
                }

                try {
                    console.log('Creating audio preview from MediaRecorder blobs');
                    console.log('Audio chunks:', this.audioChunks.length, 'total size:', this.audioChunks.reduce((sum, chunk) => sum + chunk.size, 0), 'bytes');

                    // Create blob from MediaRecorder chunks
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    this.recordedAudioBlob = audioBlob;

                    console.log('Created audio blob, size:', audioBlob.size, 'bytes, type:', audioBlob.type);

                    // Create audio element for preview
                    const audioUrl = URL.createObjectURL(audioBlob);
                    this.audioPreviewElement = new Audio(audioUrl);

                    this.audioPreviewElement.addEventListener('loadedmetadata', () => {
                        const duration = this.audioPreviewElement.duration;
                        this.audioDuration.textContent = this.formatDuration(duration);
                        console.log('Audio preview created, duration:', duration, 'seconds');

                        // Check if duration is valid
                        if (isNaN(duration) || duration === 0) {
                            console.warn('Invalid audio duration - possible audio capture issue');
                            this.showError('Audio recording issue detected. Please try again.');
                        }
                    });

                    this.audioPreviewElement.addEventListener('error', (error) => {
                        console.error('Audio preview error:', error);
                        // Don't show error to user, just log it - the audio might still be valid
                    });

                    // Show preview interface
                    this.audioPreview.style.display = 'block';
                    this.isPreviewMode = true;

                } catch (error) {
                    console.error('Error creating audio preview:', error);
                    this.showError('Failed to create audio preview: ' + error.message);
                }
            }

            // Audio level monitoring commented out since we're using Web Speech API
            /*
            startAudioLevelMonitoring(stream) {
                if (this.levelCheckInterval) {
                    clearInterval(this.levelCheckInterval);
                }

                this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                this.analyser = this.audioContext.createAnalyser();
                this.analyser.fftSize = 256;
                this.analyser.smoothingTimeConstant = 0.8;

                const source = this.audioContext.createMediaStreamSource(stream);
                source.connect(this.analyser);

                const bufferLength = this.analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);

                this.levelCheckInterval = setInterval(() => {
                    if (!this.isInCall || !this.userTurn) {
                        return;
                    }

                    this.analyser.getByteFrequencyData(dataArray);

                    // Calculate average volume level for visualization only
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const averageLevel = sum / bufferLength / 255; // Normalize to 0-1

                    // Update visualization
                    this.updateAudioVisualization(dataArray);

                    // Update level meter
                    const levelPercentage = Math.round(averageLevel * 100);
                    this.audioLevelValue.textContent = levelPercentage + '%';

                }, 100); // Check every 100ms
            }
            */

            // Audio visualization methods commented out since we're using Web Speech API
            /*
            updateAudioVisualization(dataArray) {
                for (let i = 0; i < this.audioBars.length; i++) {
                    const value = dataArray[i * 2] || 0;
                    const height = Math.max(10, (value / 255) * 50);
                    this.audioBars[i].style.height = height + 'px';
                }
            }

            stopAudioVisualization() {
                this.audioBars.forEach(bar => {
                    bar.style.height = '10px';
                });
            }
            */

            stopMicrophone() {
                if (this.scriptProcessor && this.scriptProcessor.state !== 'closed') {
                    console.log('Stopping microphone recording');
                    this.scriptProcessor.disconnect();
                    this.scriptProcessor.onaudioprocess = null;
                    this.scriptProcessor = null;
                }

                // Clean up audio level monitoring
                if (this.levelCheckInterval) {
                    console.log('Cleaning up audio level monitoring');
                    clearInterval(this.levelCheckInterval);
                    this.levelCheckInterval = null;
                }

                // Clean up recording timeout
                if (this.recordingTimeout) {
                    console.log('Cleaning up recording timeout');
                    clearTimeout(this.recordingTimeout);
                    this.recordingTimeout = null;
                }

                this.isRecording = false;
                this.recordingIndicator.style.display = 'none';
                this.stopAudioVisualization();

                // Clean up ScriptProcessor event handlers AFTER the stop() call has completed
                // The onend event handler needs to remain active to call sendAudioData()
                setTimeout(() => {
                    if (this.scriptProcessor) {
                        console.log('Cleaning up ScriptProcessor event handlers');
                        this.scriptProcessor.disconnect();
                        this.scriptProcessor = null;
                    }
                }, 100); // Small delay to ensure onend event fires
            }

            async sendAudioData() {
                console.log('Sending audio data');
                if (!this.isInCall) {
                    console.log('Not sending audio data - call not active or not recording');
                    return;
                }

                if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    console.error('WebSocket not connected, cannot send audio');
                    this.showError('WebSocket not connected');
                    return;
                }

                try {
                    console.log('Preparing to send PCM audio data, chunks:', this.audioChunks.length);

                    if (this.audioChunks.length === 0) {
                        console.log('No audio chunks to send');
                        return;
                    }

                    // Combine all PCM chunks into a single buffer
                    let totalSamples = 0;
                    this.audioChunks.forEach(chunk => {
                        totalSamples += new Int16Array(chunk).length;
                    });

                    const combinedPcmData = new Int16Array(totalSamples);
                    let offset = 0;

                    this.audioChunks.forEach(chunk => {
                        const chunkData = new Int16Array(chunk);
                        combinedPcmData.set(chunkData, offset);
                        offset += chunkData.length;
                    });

                    console.log('Combined PCM data, total samples:', combinedPcmData.length, 'bytes:', combinedPcmData.byteLength);

                    // Convert Int16Array to Uint8Array for sending
                    const audioData = new Uint8Array(combinedPcmData.buffer);

                    // Debug: Log the first few bytes to verify PCM data
                    const headerBytes = audioData.slice(0, 16);
                    console.log('PCM header bytes:', Array.from(headerBytes).map(b => b.toString(16).padStart(2, '0')).join(' '));

                    console.log('Sending LINEAR16 PCM audio data, size:', audioData.length, 'bytes');
                    this.ws.send(audioData);
                    console.log('PCM audio data sent to server');
                    this.showMessage('Audio sent', 'user');

                    // Switch to AI's turn
                    this.userTurn = false;
                    console.log('Switched to AI\'s turn');
                    this.updateTurnIndicator();

                    // Clear the chunks after sending
                    this.audioChunks = [];
                    console.log('Audio chunks cleared');

                } catch (error) {
                    console.error('Error sending audio:', error);
                    this.showError('Failed to send audio data');
                }
            }

            disconnect() {
                if (this.isInCall) {
                    this.endCall();
                }

                // Clear silence timeout
                if (this.silenceTimeout) {
                    clearTimeout(this.silenceTimeout);
                    this.silenceTimeout = null;
                }

                // Clear countdown interval
                if (this.countdownInterval) {
                    clearInterval(this.countdownInterval);
                    this.countdownInterval = null;
                }

                // Hide audio preview if it's showing
                if (this.isPreviewMode) {
                    this.hideAudioPreview();
                }

                // Clean up ScriptProcessor if it still exists
                if (this.scriptProcessor) {
                    console.log('Cleaning up ScriptProcessor on disconnect');
                    this.stopMicrophone();
                }

                // VAD is disabled, no need to clean it up
                // if (this.vad) {
                //     console.log('Cleaning up VAD on disconnect');
                //     this.vad.destroy();
                //     this.vad = null;
                //     this.isVADInitialized = false;
                // }

                // Clean up Web Speech API
                if (this.isWebSpeechListening) {
                    console.log('Cleaning up Web Speech API on disconnect');
                    this.stopWebSpeechRecognition();
                }
                this.webSpeechRecognition = null;

                // Clean up audio stream
                if (this.audioStream) {
                    console.log('Cleaning up audio stream on disconnect');
                    this.audioStream.getTracks().forEach(track => track.stop());
                    this.audioStream = null;
                }

                if (this.ws) {
                    this.ws.close();
                }

                this.updateStatus('disconnected', 'Disconnected');
                this.connectBtn.disabled = false;
                this.disconnectBtn.disabled = true;
                this.monitorToggleBtn.disabled = true;
                this.previewToggleBtn.disabled = true;
                this.pcmToggleBtn.disabled = true;
                this.webSpeechToggleBtn.disabled = true;
                this.sessionInfo.style.display = 'none';
                this.callStatus.style.display = 'none';
                this.transcriptionMode.style.display = 'none';
            }

            createAudioPreview() {
                if (this.audioChunks.length === 0) {
                    console.log('No audio chunks to preview');
                    return;
                }

                try {
                    console.log('Creating audio preview from PCM chunks');

                    // Combine all PCM chunks into a single buffer
                    let totalSamples = 0;
                    this.audioChunks.forEach(chunk => {
                        totalSamples += new Int16Array(chunk).length;
                    });

                    const combinedPcmData = new Int16Array(totalSamples);
                    let offset = 0;

                    this.audioChunks.forEach(chunk => {
                        const chunkData = new Int16Array(chunk);
                        combinedPcmData.set(chunkData, offset);
                        offset += chunkData.length;
                    });

                    // Convert PCM to WAV format for playback
                    const wavBlob = this.pcmToWav(combinedPcmData);
                    this.recordedAudioBlob = wavBlob;

                    // Create audio element for preview
                    this.audioPreviewElement = new Audio(URL.createObjectURL(wavBlob));
                    this.audioPreviewElement.addEventListener('loadedmetadata', () => {
                        const duration = this.audioPreviewElement.duration;
                        this.audioDuration.textContent = this.formatDuration(duration);
                    });

                    // Show preview interface
                    this.audioPreview.style.display = 'block';
                    this.isPreviewMode = true;

                    console.log('Audio preview created, duration:', this.audioPreviewElement.duration);
                    console.log('Audio quality info:', {
                        originalSamples: combinedPcmData.length,
                        originalDuration: combinedPcmData.length / this.sampleRate,
                        resampledDuration: this.audioPreviewElement.duration,
                        sampleRate: this.sampleRate,
                        targetSampleRate: this.targetSampleRate
                    });

                } catch (error) {
                    console.error('Error creating audio preview:', error);
                    this.showError('Failed to create audio preview');
                }
            }

            pcmToWav(pcmData) {
                // Use simple decimation for WAV creation
                const resampledData = this.resampleForWav(pcmData);

                // Create WAV header for 16-bit PCM, 16kHz, mono
                const sampleRate = this.targetSampleRate;
                const numChannels = 1;
                const bitsPerSample = 16;
                const byteRate = sampleRate * numChannels * bitsPerSample / 8;
                const blockAlign = numChannels * bitsPerSample / 8;
                const dataSize = resampledData.length * 2; // 2 bytes per sample
                const fileSize = 36 + dataSize;

                const buffer = new ArrayBuffer(44 + dataSize);
                const view = new DataView(buffer);

                // WAV header
                view.setUint32(0, 0x52494646, false); // "RIFF"
                view.setUint32(4, fileSize, true); // File size
                view.setUint32(8, 0x57415645, false); // "WAVE"
                view.setUint32(12, 0x666D7420, false); // "fmt "
                view.setUint32(16, 16, true); // Chunk size
                view.setUint16(20, 1, true); // Audio format (PCM)
                view.setUint16(22, numChannels, true); // Number of channels
                view.setUint32(24, sampleRate, true); // Sample rate
                view.setUint32(28, byteRate, true); // Byte rate
                view.setUint16(32, blockAlign, true); // Block align
                view.setUint16(34, bitsPerSample, true); // Bits per sample
                view.setUint32(36, 0x64617461, false); // "data"
                view.setUint32(40, dataSize, true); // Data size

                // Copy resampled PCM data
                const pcmBytes = new Uint8Array(resampledData.buffer);
                const wavBytes = new Uint8Array(buffer);
                wavBytes.set(pcmBytes, 44);

                return new Blob([buffer], { type: 'audio/wav' });
            }

            formatDuration(seconds) {
                const mins = Math.floor(seconds / 60);
                const secs = Math.floor(seconds % 60);
                return `${mins}:${secs.toString().padStart(2, '0')}`;
            }

            playRecordedAudio() {
                if (this.audioPreviewElement) {
                    this.audioPreviewElement.play();
                    this.playAudioBtn.disabled = true;
                    this.pauseAudioBtn.disabled = false;

                    this.audioPreviewElement.addEventListener('ended', () => {
                        this.playAudioBtn.disabled = false;
                        this.pauseAudioBtn.disabled = true;
                    }, { once: true });
                }
            }

            pauseRecordedAudio() {
                if (this.audioPreviewElement) {
                    this.audioPreviewElement.pause();
                    this.playAudioBtn.disabled = false;
                    this.pauseAudioBtn.disabled = true;
                }
            }

            sendRecordedAudio() {
                if (!this.recordedAudioBlob) {
                    console.log('No recorded audio to send');
                    this.showError('No audio recorded. Please try recording again.');
                    return;
                }

                console.log('Sending WebM audio blob to server for processing (from preview)');

                // Store the blob before hiding the preview (which clears it)
                const audioBlob = this.recordedAudioBlob;
                this.hideAudioPreview();

                // Send WebM blob directly to server
                this.sendWebmBlobToServer(audioBlob);
            }

            async sendWebmBlobToServer(webmBlob) {
                try {
                    if (!webmBlob) {
                        throw new Error('No audio blob provided');
                    }

                    console.log('Sending WebM blob to server, size:', webmBlob.size, 'bytes, type:', webmBlob.type);

                    // Check WebSocket connection state
                    if (!this.ws) {
                        console.error('WebSocket not initialized');
                        this.showError('WebSocket not initialized');
                        return;
                    }

                    console.log("WebSocket readyState:", this.ws.readyState);

                    if (this.ws.readyState !== WebSocket.OPEN) {
                        console.error('WebSocket not connected, readyState:', this.ws.readyState);
                        this.showError('WebSocket not connected');
                        return;
                    }

                    // Convert blob to base64 using FileReader (more efficient for large files)
                    const base64Audio = await this.blobToBase64(webmBlob);

                    // Send as JSON with type indicator
                    const message = {
                        type: 'webm_audio',
                        data: base64Audio,
                        mimeType: webmBlob.type,
                        size: webmBlob.size
                    };

                    this.ws.send(JSON.stringify(message));
                    console.log('WebM audio blob sent to server for ffmpeg processing');
                    this.showMessage('Audio sent', 'user');

                    // Switch to AI's turn
                    this.userTurn = false;
                    console.log('Switched to AI\'s turn');
                    this.updateTurnIndicator();

                } catch (error) {
                    console.error('Error sending WebM blob to server:', error);
                    this.showError('Failed to send audio: ' + error.message);
                }
            }

            // Helper function to convert blob to base64 efficiently
            blobToBase64(blob) {
                return new Promise((resolve, reject) => {
                    const reader = new FileReader();
                    reader.onload = () => {
                        const result = reader.result;
                        // Remove the data URL prefix (e.g., "data:audio/webm;base64,")
                        const base64 = result.split(',')[1];
                        resolve(base64);
                    };
                    reader.onerror = () => reject(new Error('Failed to read blob'));
                    reader.readAsDataURL(blob);
                });
            }

            cancelAudioPreview() {
                console.log('Canceling audio preview');
                this.hideAudioPreview();

                // Clear audio chunks and start listening again
                this.audioChunks = [];
                if (this.isInCall && this.userTurn) {
                    this.startListening();
                }
            }

            retryRecording() {
                console.log('Retrying recording');
                this.hideAudioPreview();

                // Clear audio chunks and start listening again
                this.audioChunks = [];
                if (this.isInCall && this.userTurn) {
                    this.startListening();
                }
            }

            hideAudioPreview() {
                this.audioPreview.style.display = 'none';
                this.isPreviewMode = false;

                // Clean up audio element
                if (this.audioPreviewElement) {
                    this.audioPreviewElement.pause();
                    this.audioPreviewElement.src = '';
                    this.audioPreviewElement = null;
                }

                this.recordedAudioBlob = null;
                this.playAudioBtn.disabled = false;
                this.pauseAudioBtn.disabled = true;
            }

            processAudioForSTT(inputData) {
                const outputData = new Float32Array(inputData.length);

                // Audio processing parameters - much less aggressive for better STT
                const gain = 1.0; // No gain - preserve original levels
                const noiseGate = 0.001; // Very low threshold to preserve more audio
                const compressionThreshold = 0.8; // Higher threshold - less compression
                const compressionRatio = 0.9; // Less aggressive compression

                let nonZeroSamples = 0;
                let gatedSamples = 0;

                for (let i = 0; i < inputData.length; i++) {
                    let sample = inputData[i];

                    // Apply noise gate (very gentle)
                    if (Math.abs(sample) < noiseGate) {
                        sample = 0;
                        gatedSamples++;
                    } else {
                        nonZeroSamples++;
                    }

                    // Apply gain (minimal)
                    sample *= gain;

                    // Apply dynamic range compression (very gentle)
                    if (Math.abs(sample) > compressionThreshold) {
                        const excess = Math.abs(sample) - compressionThreshold;
                        const compressedExcess = excess * compressionRatio;
                        sample = Math.sign(sample) * (compressionThreshold + compressedExcess);
                    }

                    // Clamp to valid range
                    sample = Math.max(-1, Math.min(1, sample));

                    outputData[i] = sample;
                }

                console.log(`Audio processing: ${nonZeroSamples}/${inputData.length} non-zero samples (${(nonZeroSamples / inputData.length * 100).toFixed(1)}%), ${gatedSamples} gated samples`);

                return outputData;
            }

            // Simple resampling for WAV creation
            resampleForWav(pcmData) {
                // Convert Int16Array to Float32Array for processing
                const floatData = new Float32Array(pcmData.length);
                for (let i = 0; i < pcmData.length; i++) {
                    floatData[i] = pcmData[i] / 32767; // Normalize to -1 to 1
                }

                // Simple decimation (take every 3rd sample for 48kHz to 16kHz)
                const decimationFactor = Math.round(this.sampleRate / this.targetSampleRate);
                const outputLength = Math.floor(floatData.length / decimationFactor);
                const outputData = new Float32Array(outputLength);

                for (let i = 0; i < outputLength; i++) {
                    outputData[i] = floatData[i * decimationFactor];
                }

                // Convert back to Int16Array
                const int16Output = new Int16Array(outputLength);
                for (let i = 0; i < outputLength; i++) {
                    int16Output[i] = Math.round(outputData[i] * 32767);
                }

                return int16Output;
            }

            toggleMonitoring() {
                this.monitoringEnabled = !this.monitoringEnabled;
                this.monitorToggleBtn.textContent = `üîä Monitor: ${this.monitoringEnabled ? 'ON' : 'OFF'}`;

                if (this.monitorGain) {
                    this.monitorGain.gain.value = this.monitoringEnabled ? 0.3 : 0;
                }
            }

            // Test function to validate WebSocket connection
            testWebSocketConnection() {
                if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    console.error('WebSocket not connected for test');
                    return;
                }

                console.log('Sending test message to validate WebSocket connection...');
                this.ws.send("TEST_AUDIO_PAYLOAD");
                console.log('Test message sent');
            }

            togglePreview() {
                this.isPreviewMode = !this.isPreviewMode;
                this.previewToggleBtn.textContent = `üéµ Preview: ${this.isPreviewMode ? 'ON' : 'OFF'}`;
                console.log(`Preview mode ${this.isPreviewMode ? 'enabled' : 'disabled'}`);
            }

            startPcmCapture() {
                if (this.isPcmCapturing || !this.audioStream) {
                    return;
                }

                try {
                    console.log('üé§ Starting direct PCM capture from microphone');

                    // Create audio context for PCM capture with target sample rate
                    this.pcmAudioContext = new (window.AudioContext || window.webkitAudioContext)({
                        sampleRate: this.targetSampleRate // 16kHz for STT
                    });
                    const source = this.pcmAudioContext.createMediaStreamSource(this.audioStream);

                    // Create script processor for PCM data
                    this.pcmScriptProcessor = this.pcmAudioContext.createScriptProcessor(this.bufferSize, 1, 1);

                    this.pcmScriptProcessor.onaudioprocess = (event) => {
                        if (!this.isPcmCapturing) return;

                        const inputBuffer = event.inputBuffer;
                        const inputData = inputBuffer.getChannelData(0); // Float32Array

                        // Convert Float32Array to Int16Array for STT
                        const pcmData = new Int16Array(inputData.length);
                        for (let i = 0; i < inputData.length; i++) {
                            // Clamp to valid range and convert to 16-bit
                            const sample = Math.max(-1, Math.min(1, inputData[i]));
                            pcmData[i] = Math.round(sample * 32767);
                        }

                        // Store PCM chunk
                        this.pcmChunks.push(pcmData);

                        // Keep only last 10 seconds of audio to prevent memory issues
                        const maxChunks = Math.ceil(10 * this.targetSampleRate / this.bufferSize);
                        if (this.pcmChunks.length > maxChunks) {
                            this.pcmChunks = this.pcmChunks.slice(-maxChunks);
                        }
                    };

                    // Connect the audio nodes
                    source.connect(this.pcmScriptProcessor);
                    this.pcmScriptProcessor.connect(this.pcmAudioContext.destination);

                    this.isPcmCapturing = true;
                    this.pcmChunks = [];
                    console.log('‚úÖ Direct PCM capture started at 16kHz');

                } catch (error) {
                    console.error('‚ùå Failed to start PCM capture:', error);
                }
            }

            stopPcmCapture() {
                if (!this.isPcmCapturing) {
                    return;
                }

                try {
                    console.log('üõë Stopping direct PCM capture');

                    // Disconnect and clean up script processor
                    if (this.pcmScriptProcessor) {
                        this.pcmScriptProcessor.disconnect();
                        this.pcmScriptProcessor.onaudioprocess = null;
                        this.pcmScriptProcessor = null;
                    }

                    // Close audio context
                    if (this.pcmAudioContext && this.pcmAudioContext.state !== 'closed') {
                        this.pcmAudioContext.close();
                        this.pcmAudioContext = null;
                    }

                    this.isPcmCapturing = false;
                    console.log('‚úÖ Direct PCM capture stopped');

                } catch (error) {
                    console.error('‚ùå Error stopping PCM capture:', error);
                }
            }

            getCombinedPcmData() {
                if (this.pcmChunks.length === 0) {
                    console.log('No PCM chunks to combine');
                    return null;
                }

                try {
                    // Calculate total length
                    let totalLength = 0;
                    this.pcmChunks.forEach(chunk => {
                        totalLength += chunk.length;
                    });

                    // Combine all chunks
                    const combinedPcm = new Int16Array(totalLength);
                    let offset = 0;

                    this.pcmChunks.forEach(chunk => {
                        combinedPcm.set(chunk, offset);
                        offset += chunk.length;
                    });

                    console.log(`üìä Combined PCM data: ${combinedPcm.length} samples (${(combinedPcm.length / 16000).toFixed(2)}s)`);
                    return combinedPcm;

                } catch (error) {
                    console.error('‚ùå Error combining PCM data:', error);
                    return null;
                }
            }

            sendPcmDataToServer() {
                const pcmData = this.getCombinedPcmData();
                if (!pcmData || !this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    console.log('Cannot send PCM data:', {
                        hasPcmData: !!pcmData,
                        pcmDataLength: pcmData ? pcmData.length : 0,
                        wsConnected: this.ws && this.ws.readyState === WebSocket.OPEN
                    });
                    return;
                }

                try {
                    console.log(`üì§ Sending PCM data to server: ${pcmData.length * 2} bytes`);
                    console.log('PCM data details:', {
                        samples: pcmData.length,
                        duration: (pcmData.length / 16000).toFixed(2) + 's',
                        sampleRate: 16000,
                        channels: 1,
                        bitDepth: 16
                    });

                    // Log first and last few samples for debugging
                    const firstSamples = Array.from(pcmData.slice(0, 10));
                    const lastSamples = Array.from(pcmData.slice(-10));
                    console.log('First 10 PCM samples:', firstSamples);
                    console.log('Last 10 PCM samples:', lastSamples);

                    // Convert Int16Array to Buffer/Uint8Array
                    const pcmBuffer = new Uint8Array(pcmData.buffer);

                    // Send as binary data
                    this.ws.send(pcmBuffer);

                    // Clear PCM chunks after sending
                    this.pcmChunks = [];

                    console.log('‚úÖ PCM data sent to server');
                    this.showMessage('Audio sent', 'user');

                    // Switch to AI's turn
                    this.userTurn = false;
                    console.log('Switched to AI\'s turn');
                    this.updateTurnIndicator();

                } catch (error) {
                    console.error('‚ùå Error sending PCM data:', error);
                    this.showError('Failed to send audio data');
                }
            }

            togglePcmCapture() {
                this.pcmMode = !this.pcmMode;
                this.pcmToggleBtn.textContent = `üé§ PCM: ${this.pcmMode ? 'ON' : 'OFF'}`;
                console.log(`PCM mode ${this.pcmMode ? 'enabled' : 'disabled'}`);

                // Stop any current capture when switching modes
                if (this.isPcmCapturing) {
                    this.stopPcmCapture();
                }
                if (this.isRecording) {
                    this.stopRecording();
                }
            }



            createMediaRecorder() {
                if (!this.audioStream) {
                    console.error('No audio stream available for MediaRecorder');
                    return;
                }

                const options = {
                    mimeType: 'audio/webm;codecs=opus',
                    audioBitsPerSecond: 128000 // Optimal bitrate for Opus codec
                };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    options.mimeType = 'audio/webm';
                }

                console.log('Creating new MediaRecorder instance for WebM mode');
                this.mediaRecorder = new MediaRecorder(this.audioStream, options);
                this.audioChunks = [];
                this.isRecording = false;

                this.mediaRecorder.ondataavailable = (e) => {
                    console.log('MediaRecorder data available:', e.data.size, 'bytes');
                    if (e.data.size > 0) {
                        this.audioChunks.push(e.data);

                        // Keep only the last 15 seconds of audio to ensure we have enough pre-speech capture
                        const maxChunks = 150; // 15 seconds at 100ms intervals
                        if (this.audioChunks.length > maxChunks) {
                            this.audioChunks = this.audioChunks.slice(-maxChunks);
                            console.log('Trimmed audio chunks to last 15 seconds');
                        }
                    }
                    console.log('Total audio chunks:', this.audioChunks.length);
                };

                this.mediaRecorder.onstop = () => {
                    console.log('MediaRecorder onstop event triggered');
                    const audioBlob = new Blob(this.audioChunks, { type: 'audio/webm' });
                    this.recordedAudioBlob = audioBlob;
                    console.log('MediaRecorder stopped, created blob:', audioBlob.size, 'bytes');

                    if (this.isPreviewMode) {
                        // Show preview interface
                        this.createAudioPreviewFromBlobs();
                    } else {
                        // Auto-send when preview is off
                        console.log('Preview mode off - auto-sending audio');
                        this.sendWebmBlobToServer(audioBlob);
                    }
                };
            }

            toggleWebSpeech() {
                if (!this.webSpeechSupported) {
                    this.showError('Web Speech API is not supported in this browser');
                    return;
                }

                this.webSpeechEnabled = !this.webSpeechEnabled;
                this.webSpeechToggleBtn.textContent = `üó£Ô∏è Web Speech: ${this.webSpeechEnabled ? 'ON' : 'OFF'}`;
                console.log(`Web Speech API ${this.webSpeechEnabled ? 'enabled' : 'disabled'}`);

                // Update transcription mode display
                this.updateTranscriptionModeDisplay();

                // If we're currently in a call and it's the user's turn, switch listening methods
                if (this.isInCall && this.userTurn) {
                    console.log('üîÑ Switching listening methods due to toggle...');

                    // Only restart if Web Speech API is being disabled
                    if (!this.webSpeechEnabled && this.isWebSpeechListening) {
                        console.log('üõë Stopping Web Speech API due to toggle');
                        this.stopWebSpeechRecognition();
                    } else if (this.webSpeechEnabled && !this.isWebSpeechListening) {
                        console.log('üîÑ Starting Web Speech API due to toggle');
                        setTimeout(() => {
                            this.startListening();
                        }, 500);
                    } else {
                        console.log('üîÑ Web Speech API toggle - no restart needed');
                    }
                }
            }

            updateTranscriptionModeDisplay() {
                if (this.webSpeechEnabled && this.webSpeechSupported) {
                    this.transcriptionModeValue.textContent = 'Web Speech API';
                } else {
                    this.transcriptionModeValue.textContent = 'ElevenLabs STT';
                }
            }

            initializeWebSpeechRecognition() {
                if (!this.webSpeechSupported) {
                    console.warn('Web Speech API not supported in this browser');
                    return;
                }

                // Prevent multiple initializations
                if (this.webSpeechRecognition) {
                    console.log('üó£Ô∏è Web Speech API already initialized');
                    return;
                }

                try {
                    // Use the appropriate SpeechRecognition constructor
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    this.webSpeechRecognition = new SpeechRecognition();

                    // Configure Web Speech API
                    this.webSpeechRecognition.continuous = true; // Keep listening
                    this.webSpeechRecognition.interimResults = true; // Get interim results
                    this.webSpeechRecognition.lang = 'en-US'; // English language
                    this.webSpeechRecognition.maxAlternatives = 1; // Only one result

                    // Event handlers
                    this.webSpeechRecognition.onstart = () => {
                        console.log('üó£Ô∏è Web Speech API started listening');
                        this.isWebSpeechListening = true;
                        this.recordingIndicator.style.display = 'flex';
                        this.silenceIndicator.style.display = 'none';
                    };

                    this.webSpeechRecognition.onresult = (event) => {
                        if (!this.isInCall || !this.userTurn) {
                            return;
                        }

                        let finalTranscript = '';
                        let interimTranscript = '';

                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const transcript = event.results[i][0].transcript;
                            if (event.results[i].isFinal) {
                                finalTranscript += transcript;
                            } else {
                                interimTranscript += transcript;
                            }
                        }

                        // Show interim results
                        if (interimTranscript) {
                            console.log('üó£Ô∏è Web Speech interim:', interimTranscript);
                        }

                        // Process final results
                        if (finalTranscript) {
                            console.log('üó£Ô∏è Web Speech final:', finalTranscript);
                            this.processWebSpeechResult(finalTranscript);
                        }
                    };

                    this.webSpeechRecognition.onerror = (event) => {
                        console.error('üó£Ô∏è Web Speech API error:', event.error);
                        this.isWebSpeechListening = false;

                        if (event.error === 'no-speech') {
                            // No speech detected, restart listening
                            if (this.isInCall && this.userTurn && this.webSpeechEnabled) {
                                setTimeout(() => {
                                    this.startWebSpeechRecognition();
                                }, 1000);
                            }
                        } else if (event.error === 'network') {
                            this.showError('Web Speech API network error. Please check your connection.');
                        } else if (event.error === 'not-allowed') {
                            this.showError('Microphone access denied. Please allow microphone access.');
                        } else if (event.error === 'audio-capture') {
                            this.showError('No microphone found. Please connect a microphone.');
                        } else if (event.error === 'service-not-allowed') {
                            this.showError('Speech recognition service not allowed. Please check browser settings.');
                        } else {
                            this.showError(`Web Speech API error: ${event.error}`);
                        }
                    };

                    this.webSpeechRecognition.onend = () => {
                        console.log('üó£Ô∏è Web Speech API stopped listening');
                        this.isWebSpeechListening = false;
                        this.recordingIndicator.style.display = 'none';

                        // Always restart if still in call and Web Speech is enabled
                        // Don't check userTurn here - let the onresult handler filter
                        if (this.isInCall && this.webSpeechEnabled) {
                            setTimeout(() => {
                                this.startWebSpeechRecognition();
                            }, 1000);
                        }
                    };

                    console.log('‚úÖ Web Speech API initialized successfully');

                } catch (error) {
                    console.error('‚ùå Failed to initialize Web Speech API:', error);
                    this.showError('Failed to initialize Web Speech API: ' + error.message);
                    this.webSpeechSupported = false; // Mark as not supported
                }
            }

            startWebSpeechRecognition() {
                if (!this.webSpeechEnabled) {
                    console.log('üó£Ô∏è Web Speech API disabled, not starting');
                    return;
                }

                if (this.isWebSpeechListening) {
                    console.log('üó£Ô∏è Web Speech API already listening, skipping start');
                    return;
                }

                // Initialize Web Speech API on first use (lazy initialization)
                if (!this.webSpeechRecognition) {
                    console.log('üó£Ô∏è Initializing Web Speech API on first use...');
                    this.initializeWebSpeechRecognition();

                    // If initialization failed, return
                    if (!this.webSpeechRecognition) {
                        console.error('‚ùå Web Speech API initialization failed');
                        return;
                    }
                }

                try {
                    console.log('üó£Ô∏è Starting Web Speech recognition...');
                    this.webSpeechRecognition.start();
                } catch (error) {
                    console.error('‚ùå Error starting Web Speech recognition:', error);
                }
            }

            stopWebSpeechRecognition() {
                if (!this.webSpeechRecognition || !this.isWebSpeechListening) {
                    return;
                }

                try {
                    console.log('üõë Stopping Web Speech recognition...');
                    this.webSpeechRecognition.stop();
                } catch (error) {
                    console.error('‚ùå Error stopping Web Speech recognition:', error);
                }
            }

            processWebSpeechResult(transcript) {
                if (!transcript.trim()) {
                    return;
                }

                console.log('üó£Ô∏è Processing Web Speech result:', transcript);

                // Check for very short transcriptions (likely false positives)
                if (transcript.trim().length < 1) {
                    console.log('üó£Ô∏è Skipping very short transcription:', transcript);
                    return;
                }

                // Show user message immediately
                this.showMessage(transcript, 'user');

                // Send text directly to server
                this.sendTextToServer(transcript);

                // Switch to AI's turn
                this.userTurn = false;
                console.log('Switched to AI\'s turn');
                this.updateTurnIndicator();
            }

            sendTextToServer(text) {
                if (!this.ws || this.ws.readyState !== WebSocket.OPEN) {
                    console.error('WebSocket not connected, cannot send text');
                    this.showError('WebSocket not connected');
                    return;
                }

                try {
                    console.log('üì§ Sending text to server:', text);

                    const message = {
                        type: 'text_message',
                        data: text,
                        timestamp: Date.now()
                    };

                    this.ws.send(JSON.stringify(message));
                    console.log('‚úÖ Text sent to server');

                    // Log performance comparison
                    console.log('üöÄ Web Speech API: Text sent directly (no STT processing time)');

                } catch (error) {
                    console.error('‚ùå Error sending text to server:', error);
                    this.showError('Failed to send text: ' + error.message);
                }
            }
        }

        // Initialize the client when the page loads
        document.addEventListener('DOMContentLoaded', () => {
            new VoiceAgentClient();
        });
    </script>
</body>

</html>